{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install openai-agents SDK"
      ],
      "metadata": {
        "id": "PdKwzEluDBN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai-agents"
      ],
      "metadata": {
        "id": "3QdkOviEB2ay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb63c419-7002-44b7-889c-06325bc19f85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.6/128.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/571.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.1/571.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make your Jupyter Notebook capable of running asynchronous functions."
      ],
      "metadata": {
        "id": "7yD91lz4DIAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "7A5YLi3HCfBV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Google Gemini with OPENAI-Agent SDK"
      ],
      "metadata": {
        "id": "K3VTUWDaGFcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "WBT9Z8hE6kEB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import (\n",
        "    Agent,\n",
        "    Runner,\n",
        "    function_tool,\n",
        "    set_default_openai_api,\n",
        "    set_default_openai_client,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "BASE_URL = os.getenv(\"EXAMPLE_BASE_URL\") or \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "API_KEY = os.getenv(\"EXAMPLE_API_KEY\") or userdata.get(\"GEMINI_API_KEY\")\n",
        "MODEL_NAME = os.getenv(\"EXAMPLE_MODEL_NAME\") or \"gemini-2.0-flash\"\n",
        "\n",
        "\n",
        "if not BASE_URL or not API_KEY or not MODEL_NAME:\n",
        "    raise ValueError(\n",
        "        \"Please set EXAMPLE_BASE_URL, EXAMPLE_API_KEY, EXAMPLE_MODEL_NAME via env var or code.\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    base_url=BASE_URL,\n",
        "    api_key=API_KEY,\n",
        ")\n",
        "\n",
        "set_default_openai_client(client=client, use_for_tracing=True)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "# set_tracing_disabled(disabled=True)"
      ],
      "metadata": {
        "id": "QSIWS6RvC-a4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ** Note ** Set up the custom trace processor\n",
        "```ptyhon\n",
        "local_processor = LocalTraceProcessor()\n",
        "set_trace_processors([local_processor])\n",
        "```"
      ],
      "metadata": {
        "id": "TqCujVO94rkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import AsyncOpenAI\n",
        "from agents import Agent, Runner, trace, set_default_openai_api, set_default_openai_client, set_trace_processors\n",
        "from agents.tracing.processor_interface import TracingProcessor\n",
        "from pprint import pprint\n",
        "# Custom trace processor to collect trace data locally\n",
        "class LocalTraceProcessor(TracingProcessor):\n",
        "    def __init__(self):\n",
        "        self.traces = []\n",
        "        self.spans = []\n",
        "\n",
        "    def on_trace_start(self, trace):\n",
        "        self.traces.append(trace)\n",
        "        print(f\"Trace started: {trace.trace_id}\")\n",
        "\n",
        "    def on_trace_end(self, trace):\n",
        "        print(f\"Trace ended: {trace.export()}\")\n",
        "\n",
        "    def on_span_start(self, span):\n",
        "        self.spans.append(span)\n",
        "        print(f\"Span started: {span.span_id}\")\n",
        "        print(f\"Span details: \")\n",
        "        pprint(span.export())\n",
        "\n",
        "    def on_span_end(self, span):\n",
        "        print(f\"Span ended: {span.span_id}\")\n",
        "        print(f\"Span details:\")\n",
        "        pprint(span.export())\n",
        "\n",
        "    def force_flush(self):\n",
        "        print(\"Forcing flush of trace data\")\n",
        "\n",
        "    def shutdown(self):\n",
        "        print(\"=======Shutting down trace processor========\")\n",
        "        # Print all collected trace and span data\n",
        "        print(\"Collected Traces:\")\n",
        "        for trace in self.traces:\n",
        "            print(trace.export())\n",
        "        print(\"Collected Spans:\")\n",
        "        for span in self.spans:\n",
        "            print(span.export())\n",
        "\n",
        "\n",
        "if not BASE_URL or not API_KEY or not MODEL_NAME:\n",
        "    raise ValueError(\"Please set EXAMPLE_BASE_URL, EXAMPLE_API_KEY, EXAMPLE_MODEL_NAME via env var or code.\")\n",
        "\n",
        "# Create OpenAI client\n",
        "client = AsyncOpenAI(\n",
        "    base_url=BASE_URL,\n",
        "    api_key=API_KEY,\n",
        ")\n",
        "\n",
        "# Configure the client\n",
        "set_default_openai_client(client=client, use_for_tracing=True)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "\n",
        "# Set up the custom trace processor\n",
        "local_processor = LocalTraceProcessor()\n",
        "set_trace_processors([local_processor])\n",
        "\n",
        "# Example function to run an agent and collect traces\n",
        "async def main():\n",
        "    agent = Agent(name=\"Example Agent\", instructions=\"Perform example tasks.\", model=MODEL_NAME)\n",
        "\n",
        "    with trace(\"Example workflow\"):\n",
        "        first_result = await Runner.run(agent, \"Start the task\")\n",
        "        second_result = await Runner.run(agent, f\"Rate this result: {first_result.final_output}\")\n",
        "        print(f\"Result: {first_result.final_output}\")\n",
        "        print(f\"Rating: {second_result.final_output}\")\n",
        "\n",
        "# Run the main function\n",
        "import asyncio\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0uxbKk74TbQ",
        "outputId": "8bdc26dc-42e2-4c7c-fb8f-e90109f09c20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trace started: trace_7c0bd262abab4924a3b8fce47d7dbb3a\n",
            "Span started: span_7c84732e973d47b38161f62c\n",
            "Span details: \n",
            "{'ended_at': None,\n",
            " 'error': None,\n",
            " 'id': 'span_7c84732e973d47b38161f62c',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': None,\n",
            " 'span_data': {'handoffs': [],\n",
            "               'name': 'Example Agent',\n",
            "               'output_type': 'str',\n",
            "               'tools': [],\n",
            "               'type': 'agent'},\n",
            " 'started_at': '2025-03-19T05:30:35.033805+00:00',\n",
            " 'trace_id': 'trace_7c0bd262abab4924a3b8fce47d7dbb3a'}\n",
            "Span started: span_0ecd871eb0a945a8aed68b1c\n",
            "Span details: \n",
            "{'ended_at': None,\n",
            " 'error': None,\n",
            " 'id': 'span_0ecd871eb0a945a8aed68b1c',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': 'span_7c84732e973d47b38161f62c',\n",
            " 'span_data': {'input': None,\n",
            "               'model': 'gemini-2.0-flash',\n",
            "               'model_config': {'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/',\n",
            "                                'frequency_penalty': None,\n",
            "                                'max_tokens': None,\n",
            "                                'parallel_tool_calls': False,\n",
            "                                'presence_penalty': None,\n",
            "                                'temperature': None,\n",
            "                                'tool_choice': None,\n",
            "                                'top_p': None,\n",
            "                                'truncation': None},\n",
            "               'output': None,\n",
            "               'type': 'generation',\n",
            "               'usage': None},\n",
            " 'started_at': '2025-03-19T05:30:35.034588+00:00',\n",
            " 'trace_id': 'trace_7c0bd262abab4924a3b8fce47d7dbb3a'}\n",
            "Span ended: span_0ecd871eb0a945a8aed68b1c\n",
            "Span details:\n",
            "{'ended_at': '2025-03-19T05:30:36.471766+00:00',\n",
            " 'error': None,\n",
            " 'id': 'span_0ecd871eb0a945a8aed68b1c',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': 'span_7c84732e973d47b38161f62c',\n",
            " 'span_data': {'input': [{'content': 'Perform example tasks.',\n",
            "                          'role': 'system'},\n",
            "                         {'content': 'Start the task', 'role': 'user'}],\n",
            "               'model': 'gemini-2.0-flash',\n",
            "               'model_config': {'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/',\n",
            "                                'frequency_penalty': None,\n",
            "                                'max_tokens': None,\n",
            "                                'parallel_tool_calls': False,\n",
            "                                'presence_penalty': None,\n",
            "                                'temperature': None,\n",
            "                                'tool_choice': None,\n",
            "                                'top_p': None,\n",
            "                                'truncation': None},\n",
            "               'output': [{'annotations': None,\n",
            "                           'audio': None,\n",
            "                           'content': \"Okay, I'm ready.  To get started, \"\n",
            "                                      \"please tell me what kind of task you'd \"\n",
            "                                      'like me to perform. For example, you '\n",
            "                                      'could ask me to:\\n'\n",
            "                                      '\\n'\n",
            "                                      '*   **Write something:** \"Write a short '\n",
            "                                      'poem about autumn leaves.\"\\n'\n",
            "                                      '*   **Summarize something:** \"Summarize '\n",
            "                                      'the plot of the movie *The Shawshank '\n",
            "                                      'Redemption*.\"\\n'\n",
            "                                      '*   **Translate something:** \"Translate '\n",
            "                                      '\\'Hello, how are you?\\' into Spanish.\"\\n'\n",
            "                                      '*   **Answer a question:** \"What is the '\n",
            "                                      'capital of France?\"\\n'\n",
            "                                      '*   **Generate code:** \"Write a Python '\n",
            "                                      'function that calculates the factorial '\n",
            "                                      'of a number.\"\\n'\n",
            "                                      '*   **Brainstorm ideas:** \"Brainstorm '\n",
            "                                      'ideas for a birthday party for a '\n",
            "                                      '10-year-old.\"\\n'\n",
            "                                      '\\n'\n",
            "                                      'The more specific you are, the better I '\n",
            "                                      'can perform the task.  Let me know what '\n",
            "                                      \"you'd like me to do!\\n\",\n",
            "                           'function_call': None,\n",
            "                           'refusal': None,\n",
            "                           'role': 'assistant',\n",
            "                           'tool_calls': None}],\n",
            "               'type': 'generation',\n",
            "               'usage': {'input_tokens': 7, 'output_tokens': 185}},\n",
            " 'started_at': '2025-03-19T05:30:35.034588+00:00',\n",
            " 'trace_id': 'trace_7c0bd262abab4924a3b8fce47d7dbb3a'}\n",
            "Span ended: span_7c84732e973d47b38161f62c\n",
            "Span details:\n",
            "{'ended_at': '2025-03-19T05:30:36.473259+00:00',\n",
            " 'error': None,\n",
            " 'id': 'span_7c84732e973d47b38161f62c',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': None,\n",
            " 'span_data': {'handoffs': [],\n",
            "               'name': 'Example Agent',\n",
            "               'output_type': 'str',\n",
            "               'tools': [],\n",
            "               'type': 'agent'},\n",
            " 'started_at': '2025-03-19T05:30:35.033805+00:00',\n",
            " 'trace_id': 'trace_7c0bd262abab4924a3b8fce47d7dbb3a'}\n",
            "Span started: span_f7f12aed4a3c4aacb98fe2e3\n",
            "Span details: \n",
            "{'ended_at': None,\n",
            " 'error': None,\n",
            " 'id': 'span_f7f12aed4a3c4aacb98fe2e3',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': None,\n",
            " 'span_data': {'handoffs': [],\n",
            "               'name': 'Example Agent',\n",
            "               'output_type': 'str',\n",
            "               'tools': [],\n",
            "               'type': 'agent'},\n",
            " 'started_at': '2025-03-19T05:30:36.473643+00:00',\n",
            " 'trace_id': 'trace_7c0bd262abab4924a3b8fce47d7dbb3a'}\n",
            "Span started: span_c06387bbd6bb40e7ac17aae2\n",
            "Span details: \n",
            "{'ended_at': None,\n",
            " 'error': None,\n",
            " 'id': 'span_c06387bbd6bb40e7ac17aae2',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': 'span_f7f12aed4a3c4aacb98fe2e3',\n",
            " 'span_data': {'input': None,\n",
            "               'model': 'gemini-2.0-flash',\n",
            "               'model_config': {'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/',\n",
            "                                'frequency_penalty': None,\n",
            "                                'max_tokens': None,\n",
            "                                'parallel_tool_calls': False,\n",
            "                                'presence_penalty': None,\n",
            "                                'temperature': None,\n",
            "                                'tool_choice': None,\n",
            "                                'top_p': None,\n",
            "                                'truncation': None},\n",
            "               'output': None,\n",
            "               'type': 'generation',\n",
            "               'usage': None},\n",
            " 'started_at': '2025-03-19T05:30:36.474164+00:00',\n",
            " 'trace_id': 'trace_7c0bd262abab4924a3b8fce47d7dbb3a'}\n",
            "Span ended: span_c06387bbd6bb40e7ac17aae2\n",
            "Span details:\n",
            "{'ended_at': '2025-03-19T05:30:38.427848+00:00',\n",
            " 'error': None,\n",
            " 'id': 'span_c06387bbd6bb40e7ac17aae2',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': 'span_f7f12aed4a3c4aacb98fe2e3',\n",
            " 'span_data': {'input': [{'content': 'Perform example tasks.',\n",
            "                          'role': 'system'},\n",
            "                         {'content': \"Rate this result: Okay, I'm ready.  To \"\n",
            "                                     'get started, please tell me what kind of '\n",
            "                                     \"task you'd like me to perform. For \"\n",
            "                                     'example, you could ask me to:\\n'\n",
            "                                     '\\n'\n",
            "                                     '*   **Write something:** \"Write a short '\n",
            "                                     'poem about autumn leaves.\"\\n'\n",
            "                                     '*   **Summarize something:** \"Summarize '\n",
            "                                     'the plot of the movie *The Shawshank '\n",
            "                                     'Redemption*.\"\\n'\n",
            "                                     '*   **Translate something:** \"Translate '\n",
            "                                     '\\'Hello, how are you?\\' into Spanish.\"\\n'\n",
            "                                     '*   **Answer a question:** \"What is the '\n",
            "                                     'capital of France?\"\\n'\n",
            "                                     '*   **Generate code:** \"Write a Python '\n",
            "                                     'function that calculates the factorial '\n",
            "                                     'of a number.\"\\n'\n",
            "                                     '*   **Brainstorm ideas:** \"Brainstorm '\n",
            "                                     'ideas for a birthday party for a '\n",
            "                                     '10-year-old.\"\\n'\n",
            "                                     '\\n'\n",
            "                                     'The more specific you are, the better I '\n",
            "                                     'can perform the task.  Let me know what '\n",
            "                                     \"you'd like me to do!\\n\",\n",
            "                          'role': 'user'}],\n",
            "               'model': 'gemini-2.0-flash',\n",
            "               'model_config': {'base_url': 'https://generativelanguage.googleapis.com/v1beta/openai/',\n",
            "                                'frequency_penalty': None,\n",
            "                                'max_tokens': None,\n",
            "                                'parallel_tool_calls': False,\n",
            "                                'presence_penalty': None,\n",
            "                                'temperature': None,\n",
            "                                'tool_choice': None,\n",
            "                                'top_p': None,\n",
            "                                'truncation': None},\n",
            "               'output': [{'annotations': None,\n",
            "                           'audio': None,\n",
            "                           'content': \"Okay, here's a breakdown of the \"\n",
            "                                      'response and a rating:\\n'\n",
            "                                      '\\n'\n",
            "                                      '**Strengths:**\\n'\n",
            "                                      '\\n'\n",
            "                                      '*   **Clear and Understandable:** The '\n",
            "                                      'language is simple and easy to follow.\\n'\n",
            "                                      '*   **Helpful Introduction:**  \"Okay, '\n",
            "                                      'I\\'m ready\" gives a positive and '\n",
            "                                      'welcoming tone.\\n'\n",
            "                                      '*   **Illustrative Examples:**  The '\n",
            "                                      'bullet points provide concrete examples '\n",
            "                                      'of the types of tasks the model can '\n",
            "                                      'handle. This is *very* helpful for the '\n",
            "                                      'user.\\n'\n",
            "                                      '*   **Guidance for Better Results:**  '\n",
            "                                      'The statement \"The more specific you '\n",
            "                                      'are, the better I can perform the task\" '\n",
            "                                      'sets realistic expectations and '\n",
            "                                      'encourages the user to provide detailed '\n",
            "                                      'prompts.\\n'\n",
            "                                      '*   **Comprehensive Coverage:** The '\n",
            "                                      'examples cover a range of common use '\n",
            "                                      'cases (writing, summarizing, '\n",
            "                                      'translating, answering questions, '\n",
            "                                      'generating code, brainstorming).\\n'\n",
            "                                      '\\n'\n",
            "                                      '**Weaknesses:**\\n'\n",
            "                                      '\\n'\n",
            "                                      '*   **Slightly Generic:** While '\n",
            "                                      'helpful, the response lacks any '\n",
            "                                      'personalized touch.\\n'\n",
            "                                      '*   **Could be More Concise:** While '\n",
            "                                      'the explanation is thorough, it could '\n",
            "                                      'be slightly more succinct without '\n",
            "                                      'losing clarity.\\n'\n",
            "                                      '\\n'\n",
            "                                      '**Overall Rating:**\\n'\n",
            "                                      '\\n'\n",
            "                                      '**4.5 / 5**\\n'\n",
            "                                      '\\n'\n",
            "                                      '**Justification:**\\n'\n",
            "                                      '\\n'\n",
            "                                      'This is a very good response. It '\n",
            "                                      'effectively communicates the '\n",
            "                                      'capabilities of the AI and provides '\n",
            "                                      'clear instructions on how to use it. '\n",
            "                                      'The examples are excellent. The only '\n",
            "                                      'minor issue is a slight lack of '\n",
            "                                      'personality and potential for greater '\n",
            "                                      \"conciseness. It's a functional and \"\n",
            "                                      'well-designed response that would be '\n",
            "                                      'helpful to most users.\\n',\n",
            "                           'function_call': None,\n",
            "                           'refusal': None,\n",
            "                           'role': 'assistant',\n",
            "                           'tool_calls': None}],\n",
            "               'type': 'generation',\n",
            "               'usage': {'input_tokens': 193, 'output_tokens': 296}},\n",
            " 'started_at': '2025-03-19T05:30:36.474164+00:00',\n",
            " 'trace_id': 'trace_7c0bd262abab4924a3b8fce47d7dbb3a'}\n",
            "Span ended: span_f7f12aed4a3c4aacb98fe2e3\n",
            "Span details:\n",
            "{'ended_at': '2025-03-19T05:30:38.429559+00:00',\n",
            " 'error': None,\n",
            " 'id': 'span_f7f12aed4a3c4aacb98fe2e3',\n",
            " 'object': 'trace.span',\n",
            " 'parent_id': None,\n",
            " 'span_data': {'handoffs': [],\n",
            "               'name': 'Example Agent',\n",
            "               'output_type': 'str',\n",
            "               'tools': [],\n",
            "               'type': 'agent'},\n",
            " 'started_at': '2025-03-19T05:30:36.473643+00:00',\n",
            " 'trace_id': 'trace_7c0bd262abab4924a3b8fce47d7dbb3a'}\n",
            "Result: Okay, I'm ready.  To get started, please tell me what kind of task you'd like me to perform. For example, you could ask me to:\n",
            "\n",
            "*   **Write something:** \"Write a short poem about autumn leaves.\"\n",
            "*   **Summarize something:** \"Summarize the plot of the movie *The Shawshank Redemption*.\"\n",
            "*   **Translate something:** \"Translate 'Hello, how are you?' into Spanish.\"\n",
            "*   **Answer a question:** \"What is the capital of France?\"\n",
            "*   **Generate code:** \"Write a Python function that calculates the factorial of a number.\"\n",
            "*   **Brainstorm ideas:** \"Brainstorm ideas for a birthday party for a 10-year-old.\"\n",
            "\n",
            "The more specific you are, the better I can perform the task.  Let me know what you'd like me to do!\n",
            "\n",
            "Rating: Okay, here's a breakdown of the response and a rating:\n",
            "\n",
            "**Strengths:**\n",
            "\n",
            "*   **Clear and Understandable:** The language is simple and easy to follow.\n",
            "*   **Helpful Introduction:**  \"Okay, I'm ready\" gives a positive and welcoming tone.\n",
            "*   **Illustrative Examples:**  The bullet points provide concrete examples of the types of tasks the model can handle. This is *very* helpful for the user.\n",
            "*   **Guidance for Better Results:**  The statement \"The more specific you are, the better I can perform the task\" sets realistic expectations and encourages the user to provide detailed prompts.\n",
            "*   **Comprehensive Coverage:** The examples cover a range of common use cases (writing, summarizing, translating, answering questions, generating code, brainstorming).\n",
            "\n",
            "**Weaknesses:**\n",
            "\n",
            "*   **Slightly Generic:** While helpful, the response lacks any personalized touch.\n",
            "*   **Could be More Concise:** While the explanation is thorough, it could be slightly more succinct without losing clarity.\n",
            "\n",
            "**Overall Rating:**\n",
            "\n",
            "**4.5 / 5**\n",
            "\n",
            "**Justification:**\n",
            "\n",
            "This is a very good response. It effectively communicates the capabilities of the AI and provides clear instructions on how to use it. The examples are excellent. The only minor issue is a slight lack of personality and potential for greater conciseness. It's a functional and well-designed response that would be helpful to most users.\n",
            "\n",
            "Trace ended: {'object': 'trace', 'id': 'trace_7c0bd262abab4924a3b8fce47d7dbb3a', 'workflow_name': 'Example workflow', 'group_id': None, 'metadata': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W8Q2_IOV4c69"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LkkDsV_w4c-x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y4CpOQfx4dBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rT9Ici2W4TiC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lk3E7nQm4TlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9VtXiYKb1hyP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}