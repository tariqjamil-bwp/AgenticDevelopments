{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbZrE7w7_0QH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import rich\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "openai = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "9Ac1YqyzAQiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Completion API\n",
        "\n",
        "https://platform.openai.com/docs/quickstart?api-mode=chat"
      ],
      "metadata": {
        "id": "gx38TCA9AWw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    { \"role\": \"user\", \"content\": \"Tell me a joke about the internet\"}\n",
        "]\n",
        "\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages= prompts\n",
        ")"
      ],
      "metadata": {
        "id": "pUFXJvCFAZbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rich.print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "WZK18mXFAh4W",
        "outputId": "155d2013-3b2c-4205-e1e1-ecf264a078cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mChatCompletion\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mid\u001b[0m=\u001b[32m'chatcmpl-BEJrtM5Czxy9m29c88zlYyCFHMOKS'\u001b[0m,\n",
              "    \u001b[33mchoices\u001b[0m=\u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mChoice\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mfinish_reason\u001b[0m=\u001b[32m'stop'\u001b[0m,\n",
              "            \u001b[33mindex\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
              "            \u001b[33mlogprobs\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "            \u001b[33mmessage\u001b[0m=\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
              "                \u001b[33mcontent\u001b[0m=\u001b[32m'Why did the computer keep freezing?\\n\\nBecause it left its Windows open!'\u001b[0m,\n",
              "                \u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "                \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
              "                \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "                \u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "                \u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "                \u001b[33mtool_calls\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
              "            \u001b[1m)\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[33mcreated\u001b[0m=\u001b[1;36m1742752665\u001b[0m,\n",
              "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,\n",
              "    \u001b[33mobject\u001b[0m=\u001b[32m'chat.completion'\u001b[0m,\n",
              "    \u001b[33mservice_tier\u001b[0m=\u001b[32m'default'\u001b[0m,\n",
              "    \u001b[33msystem_fingerprint\u001b[0m=\u001b[32m'fp_b8bc95a0ac'\u001b[0m,\n",
              "    \u001b[33musage\u001b[0m=\u001b[1;35mCompletionUsage\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[33mcompletion_tokens\u001b[0m=\u001b[1;36m15\u001b[0m,\n",
              "        \u001b[33mprompt_tokens\u001b[0m=\u001b[1;36m14\u001b[0m,\n",
              "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m29\u001b[0m,\n",
              "        \u001b[33mcompletion_tokens_details\u001b[0m=\u001b[1;35mCompletionTokensDetails\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33maccepted_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
              "            \u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
              "            \u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m,\n",
              "            \u001b[33mrejected_prediction_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\n",
              "        \u001b[1m)\u001b[0m,\n",
              "        \u001b[33mprompt_tokens_details\u001b[0m=\u001b[1;35mPromptTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33maudio_tokens\u001b[0m=\u001b[1;36m0\u001b[0m, \u001b[33mcached_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\n",
              "    \u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletion</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chatcmpl-BEJrtM5Czxy9m29c88zlYyCFHMOKS'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">choices</span>=<span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Choice</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">finish_reason</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">index</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">logprobs</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">message</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Why did the computer keep freezing?\\n\\nBecause it left its Windows open!'</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "                <span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
              "            <span style=\"font-weight: bold\">)</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">created</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742752665</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'chat.completion'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">service_tier</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'default'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">system_fingerprint</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'fp_b8bc95a0ac'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionUsage</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">completion_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CompletionTokensDetails</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">accepted_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">rejected_prediction_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "        <span style=\"font-weight: bold\">)</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">prompt_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">audio_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">cached_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0])\n",
        "print()\n",
        "print(response.choices[0].finish_reason)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1prP4CUA6bG",
        "outputId": "ce620af3-689d-41ed-f925-76812771b68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Why did the computer keep freezing?\\n\\nBecause it left its Windows open!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))\n",
            "\n",
            "stop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message)\n",
        "print(response.choices[0].message.function_call)\n",
        "print(response.choices[0].message.tool_calls)\n",
        "print(response.choices[0].message.annotations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXgcm8luBKDo",
        "outputId": "de4f30e4-22de-4cfa-c1f9-f36597c0632f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Why did the computer keep freezing?\\n\\nBecause it left its Windows open!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n",
            "None\n",
            "None\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrjwnXNoBMU6",
        "outputId": "d4ed17cf-aaa8-43b7-e524-f1fd3c6977f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the computer keep freezing?\n",
            "\n",
            "Because it left its Windows open!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Responses API\n",
        "\n",
        "https://platform.openai.com/docs/quickstart?api-mode=responses"
      ],
      "metadata": {
        "id": "Ucc1tuo-BONR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.responses.create(\n",
        "    model=MODEL,\n",
        "    input=\"Tell me a joke about the internet\" # Note: Now we can send user prompt directly as string to input property\n",
        ")"
      ],
      "metadata": {
        "id": "H9AUXSSTBU_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.output_text) # Simple way to access the response text from model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqRULFsCBjPk",
        "outputId": "400e2a4d-6dd7-4882-b9fa-6b7e5f6fc77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the computer go to therapy?\n",
            "\n",
            "Because it had too many tabs open!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rich.print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "482yrYq3BYDv",
        "outputId": "f7a96e55-2cc1-43f2-d5a0-83cb351ce630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mResponse\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mid\u001b[0m=\u001b[32m'resp_67e04bb93ebc8192a199b7076b88c4e60d9f31973b2a1dca'\u001b[0m,\n",
              "    \u001b[33mcreated_at\u001b[0m=\u001b[1;36m1742752697\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
              "    \u001b[33merror\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mincomplete_details\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33minstructions\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[33mmodel\u001b[0m=\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,\n",
              "    \u001b[33mobject\u001b[0m=\u001b[32m'response'\u001b[0m,\n",
              "    \u001b[33moutput\u001b[0m=\u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mResponseOutputMessage\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mid\u001b[0m=\u001b[32m'msg_67e04bb9fb208192826000de909fb2f40d9f31973b2a1dca'\u001b[0m,\n",
              "            \u001b[33mcontent\u001b[0m=\u001b[1m[\u001b[0m\n",
              "                \u001b[1;35mResponseOutputText\u001b[0m\u001b[1m(\u001b[0m\n",
              "                    \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "                    \u001b[33mtext\u001b[0m=\u001b[32m'Why did the computer go to therapy?\\n\\nBecause it had too many tabs open!'\u001b[0m,\n",
              "                    \u001b[33mtype\u001b[0m=\u001b[32m'output_text'\u001b[0m\n",
              "                \u001b[1m)\u001b[0m\n",
              "            \u001b[1m]\u001b[0m,\n",
              "            \u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
              "            \u001b[33mstatus\u001b[0m=\u001b[32m'completed'\u001b[0m,\n",
              "            \u001b[33mtype\u001b[0m=\u001b[32m'message'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[33mparallel_tool_calls\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
              "    \u001b[33mtemperature\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
              "    \u001b[33mtool_choice\u001b[0m=\u001b[32m'auto'\u001b[0m,\n",
              "    \u001b[33mtools\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mtop_p\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m,\n",
              "    \u001b[33mmax_output_tokens\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mprevious_response_id\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mreasoning\u001b[0m=\u001b[1;35mReasoning\u001b[0m\u001b[1m(\u001b[0m\u001b[33meffort\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mgenerate_summary\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[33mstatus\u001b[0m=\u001b[32m'completed'\u001b[0m,\n",
              "    \u001b[33mtext\u001b[0m=\u001b[1;35mResponseTextConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mformat\u001b[0m=\u001b[1;35mResponseFormatText\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'text'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[33mtruncation\u001b[0m=\u001b[32m'disabled'\u001b[0m,\n",
              "    \u001b[33musage\u001b[0m=\u001b[1;35mResponseUsage\u001b[0m\u001b[1m(\u001b[0m\n",
              "        \u001b[33minput_tokens\u001b[0m=\u001b[1;36m32\u001b[0m,\n",
              "        \u001b[33moutput_tokens\u001b[0m=\u001b[1;36m17\u001b[0m,\n",
              "        \u001b[33moutput_tokens_details\u001b[0m=\u001b[1;35mOutputTokensDetails\u001b[0m\u001b[1m(\u001b[0m\u001b[33mreasoning_tokens\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m,\n",
              "        \u001b[33mtotal_tokens\u001b[0m=\u001b[1;36m49\u001b[0m,\n",
              "        \u001b[33minput_tokens_details\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'cached_tokens'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n",
              "    \u001b[1m)\u001b[0m,\n",
              "    \u001b[33muser\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mstore\u001b[0m=\u001b[3;92mTrue\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Response</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'resp_67e04bb93ebc8192a199b7076b88c4e60d9f31973b2a1dca'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1742752697.0</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">error</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">incomplete_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">instructions</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{}</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">object</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'response'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">output</span>=<span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseOutputMessage</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'msg_67e04bb9fb208192826000de909fb2f40d9f31973b2a1dca'</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"font-weight: bold\">[</span>\n",
              "                <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseOutputText</span><span style=\"font-weight: bold\">(</span>\n",
              "                    <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
              "                    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Why did the computer go to therapy?\\n\\nBecause it had too many tabs open!'</span>,\n",
              "                    <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'output_text'</span>\n",
              "                <span style=\"font-weight: bold\">)</span>\n",
              "            <span style=\"font-weight: bold\">]</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'message'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">parallel_tool_calls</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">tool_choice</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'auto'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">tools</span>=<span style=\"font-weight: bold\">[]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">top_p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">max_output_tokens</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">previous_response_id</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">reasoning</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Reasoning</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">effort</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">generate_summary</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseTextConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">format</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseFormatText</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span><span style=\"font-weight: bold\">))</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">truncation</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'disabled'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">usage</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseUsage</span><span style=\"font-weight: bold\">(</span>\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">input_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">output_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">output_tokens_details</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OutputTokensDetails</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">reasoning_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">total_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">input_tokens_details</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'cached_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">user</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">store</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.tool_choice)\n",
        "print(response.tools)\n",
        "print(response.status)\n",
        "print(response.store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YzIYURQBaeh",
        "outputId": "c885c077-1fc5-474d-caf8-ef745457e851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auto\n",
            "[]\n",
            "completed\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.output)\n",
        "print(response.output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0fzHlvdBfZl",
        "outputId": "3eef2290-227b-4c6c-c5d1-cc70314e08af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResponseOutputMessage(id='msg_67e04bb9fb208192826000de909fb2f40d9f31973b2a1dca', content=[ResponseOutputText(annotations=[], text='Why did the computer go to therapy?\\n\\nBecause it had too many tabs open!', type='output_text')], role='assistant', status='completed', type='message')]\n",
            "ResponseOutputMessage(id='msg_67e04bb9fb208192826000de909fb2f40d9f31973b2a1dca', content=[ResponseOutputText(annotations=[], text='Why did the computer go to therapy?\\n\\nBecause it had too many tabs open!', type='output_text')], role='assistant', status='completed', type='message')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rich.print(response.output[0].content[0])\n",
        "print(response.output[0].content[0].type)\n",
        "print(response.output[0].content[0].text)\n",
        "# print(response.output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "JkyeEIFRBg4h",
        "outputId": "2e11e88f-6522-4c52-ada6-a5256b0b5530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mResponseOutputText\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mtext\u001b[0m=\u001b[32m'Why did the computer go to therapy?\\n\\nBecause it had too many tabs open!'\u001b[0m,\n",
              "    \u001b[33mtype\u001b[0m=\u001b[32m'output_text'\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ResponseOutputText</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Why did the computer go to therapy?\\n\\nBecause it had too many tabs open!'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'output_text'</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output_text\n",
            "Why did the computer go to therapy?\n",
            "\n",
            "Because it had too many tabs open!\n"
          ]
        }
      ]
    }
  ]
}