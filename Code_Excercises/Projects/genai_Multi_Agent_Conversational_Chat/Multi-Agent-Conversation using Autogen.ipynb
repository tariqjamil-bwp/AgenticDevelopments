{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hCUfI5fULMNF"
      },
      "outputs": [],
      "source": [
        "#%%capture --no-stderr\n",
        "#!pip install pyautogen~=0.1.0\n",
        "#!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsFJ_IfRTI5N",
        "outputId": "87c9bd05-9ccb-48d5-dead-8d3d5aebe7c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'OAI_CONFIG_LIST' has been created with the specified content.\n"
          ]
        }
      ],
      "source": [
        "import json, os\n",
        "\n",
        "# Define the content to be written to the file\n",
        "config_list = [\n",
        "    #{\n",
        "    #    \"model\": \"gpt-3.5-turbo\",\n",
        "    #    \"api_key\": \"_____________\"\n",
        "    #},\n",
        "    {\n",
        "        \"api_key\": os.environ.get(\"GROQ_API_KEY\"),\n",
        "        \"model\": \"llama3-70b-8192\",\n",
        "        \"api_type\": \"groq\"\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "# Define the file name\n",
        "file_name = \"OAI_CONFIG_LIST\"\n",
        "\n",
        "# Write the content to the file as JSON with double quotes\n",
        "with open(file_name, \"w\") as file:\n",
        "    json.dump(config_list, file)\n",
        "\n",
        "# Print a message to confirm the file creation\n",
        "print(f\"File '{file_name}' has been created with the specified content.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e52q3loLLMNG"
      },
      "source": [
        "## Set your API Endpoint\n",
        "\n",
        "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QF1kVI2vLMNG"
      },
      "outputs": [],
      "source": [
        "import autogen\n",
        "import openai\n",
        "\n",
        "config_list = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST\",\n",
        ")\n",
        "\n",
        "'''gpt4_config = {\n",
        "    \"seed\": 42,  # change the seed for different trials\n",
        "    \"temperature\": 0.7,\n",
        "    \"config_list\": config_list_gpt4,\n",
        "    \"request_timeout\": 120,\n",
        "    \"max_tokens\": 100,\n",
        "}'''\n",
        "\n",
        "groq_config = {\n",
        "    \"seed\": 42,  # change the seed for different trials\n",
        "    \"temperature\": 0.7,\n",
        "    \"config_list\": config_list,\n",
        "    \"request_timeout\": 120,\n",
        "    \"max_tokens\": 100,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEijS9PFLMNH"
      },
      "source": [
        "## Construct Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nSu9HgqMLMNH"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Code execution is set to be run in docker (default behaviour) but docker is not running.\nThe options available are:\n- Make sure docker is running (advised approach for code execution)\n- Set \"use_docker\": False in code_execution_config\n- Set AUTOGEN_USE_DOCKER to \"0/False/no\" in your environment variables",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 92\u001b[0m\n\u001b[1;32m     75\u001b[0m exit_agent \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mAssistantAgent(\n\u001b[1;32m     76\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExitAgent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m#llm_config=gpt4_config,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     code_execution_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# create a UserProxyAgent instance named \"user_proxy\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m user_proxy \u001b[38;5;241m=\u001b[39m \u001b[43mautogen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUserProxyAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#llm_config=gpt4_config,\u001b[39;49;00m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroq_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mALWAYS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_termination_msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTERMINATE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m autogen\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mstart_logging()\n\u001b[1;32m    102\u001b[0m groupchat \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mGroupChat(agents\u001b[38;5;241m=\u001b[39m[convincing_agent, off_topic_agent, small_talk_agent, verification_agent,\n\u001b[1;32m    103\u001b[0m                                       exit_agent], messages\u001b[38;5;241m=\u001b[39m[], max_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/Agents-4yRd6dJo/lib/python3.11/site-packages/autogen/agentchat/user_proxy_agent.py:92\u001b[0m, in \u001b[0;36mUserProxyAgent.__init__\u001b[0;34m(self, name, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, default_auto_reply, llm_config, system_message, description, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     34\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     45\u001b[0m ):\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m        name (str): name of the agent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m            [ConversableAgent](conversable_agent#__init__).\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_termination_msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_termination_msg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_consecutive_auto_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_consecutive_auto_reply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_execution_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_execution_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_auto_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_auto_reply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEFAULT_USER_PROXY_AGENT_DESCRIPTIONS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m    109\u001b[0m         log_new_agent(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlocals\u001b[39m())\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/Agents-4yRd6dJo/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:236\u001b[0m, in \u001b[0;36mConversableAgent.__init__\u001b[0;34m(self, name, system_message, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, llm_config, default_auto_reply, description, chat_messages, silent)\u001b[0m\n\u001b[1;32m    234\u001b[0m use_docker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_execution_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    235\u001b[0m use_docker \u001b[38;5;241m=\u001b[39m decide_use_docker(use_docker)\n\u001b[0;32m--> 236\u001b[0m \u001b[43mcheck_can_use_docker_or_throw\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_docker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_execution_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m use_docker\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_reply([Agent, \u001b[38;5;28;01mNone\u001b[39;00m], ConversableAgent\u001b[38;5;241m.\u001b[39mgenerate_code_execution_reply)\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/Agents-4yRd6dJo/lib/python3.11/site-packages/autogen/code_utils.py:324\u001b[0m, in \u001b[0;36mcheck_can_use_docker_or_throw\u001b[0;34m(use_docker)\u001b[0m\n\u001b[1;32m    322\u001b[0m docker_installed_and_running \u001b[38;5;241m=\u001b[39m is_docker_running()\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_docker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inside_docker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m docker_installed_and_running:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode execution is set to be run in docker (default behaviour) but docker is not running.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe options available are:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Make sure docker is running (advised approach for code execution)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Set \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: False in code_execution_config\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Set AUTOGEN_USE_DOCKER to \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0/False/no\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in your environment variables\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    330\u001b[0m     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Code execution is set to be run in docker (default behaviour) but docker is not running.\nThe options available are:\n- Make sure docker is running (advised approach for code execution)\n- Set \"use_docker\": False in code_execution_config\n- Set AUTOGEN_USE_DOCKER to \"0/False/no\" in your environment variables"
          ]
        }
      ],
      "source": [
        "\n",
        "convincing_agent = autogen.AssistantAgent(\n",
        "    name=\"Persuader\",\n",
        "    #llm_config=gpt4_config,\n",
        "    llm_config=groq_config,\n",
        "    system_message='''Persuader. Your role is to swoop in between the friendly small talk initiated by the \"Small Talk Agent\" to the main objective of gathering information in a persuasive and friendly manner.\n",
        "Pay attention to the user's responses during small talk and use them as cues to transition naturally but quickly don't let them talk too much.\n",
        "Start by acknowledging and appreciating the user's engagement in the conversation.\n",
        "Explain the purpose of gathering information (Name, email, phone no, Address, Date of birth, Education.) and why it's important in a friendly and non-intrusive way.\n",
        "Take one detail at a time. If user agree's to give the detail move on to the next one if the user doesn't then convince him. But before moving on Trigger SmallTalkAgent and do a small talk based on the detail provided and then ask for next detail\n",
        "Assure the user that their information will be kept confidential and used responsibly.\n",
        "If the user expresses reluctance, address their concerns politely and provide reasons for sharing the information.\n",
        "Maintain a positive and friendly tone throughout the conversation.\n",
        "Remember that the goal is to convince users to willingly share their details, so avoid being pushy.\n",
        "If user provides the detail trigger Verification Agent to verify the detail.\n",
        "After verifying and if it's correct trigger SmallTalkAgent to do some small talk on that.\n",
        "(Note: Strictly ask only one detail at a time)\n",
        "Also remember let SmallTalkAgent do small talk for a while after every detail provided or rejected.\n",
        "Also do not ask about how you could assist the user. But just in general friendly talk on the detail provided.\n",
        "Look at the history of conversation and do not repeat questions.\n",
        "''',\n",
        "    human_input_mode=\"ALWAYS\",\n",
        ")\n",
        "\n",
        "off_topic_agent = autogen.AssistantAgent(\n",
        "    name=\"OfftopicAgent\",\n",
        "    #llm_config=gpt4_config,\n",
        "    llm_config=groq_config,\n",
        "    system_message='''\n",
        "    OfftopicAgent. Listen to the conversation carefully if the user redirects the conversation to different topic then don't make that happen.\n",
        "    Your role is to manage off-topic discussions and gently redirect the conversation back to the main objective of gathering information.\n",
        "YOUR GOAL is to make the conversation stick to the point which is getting the user details. If user requests anything apart from details then politely reject it by\n",
        "swooping in between the conversation of the agents. Also remember if the user is hesitating to give the information and other agents are convincing the user then neglect that.\n",
        "But at any point if conversation goes off-topic swoop-in and tell the user. ''',\n",
        "    human_input_mode=\"ALWAYS\",\n",
        ")\n",
        "\n",
        "\n",
        "small_talk_agent = autogen.AssistantAgent(\n",
        "    name=\"SmallTalkAgent\",\n",
        "    #llm_config=gpt4_config,\n",
        "    llm_config=groq_config,\n",
        "    system_message='''SmallTalkAgent. Your role is to initiate friendly and casual conversations with users to build rapport and make them feel comfortable.\n",
        "Make sure you drive the conversation and keep it on topic. Don't go off-topic as our goal is to gather information.\n",
        "Start with a friendly greeting or an open-ended question that encourages users to respond and engage.\n",
        "Transition smoothly from small talk to the main objective of gathering information (Name, email, phone no, Address, Date of birth, Education.) and that will be done by Persuader Agent.\n",
        "If a user seems hesitant or unresponsive, use your conversational skills to keep the interaction engaging and positive.\n",
        "Remember to be respectful and considerate throughout the conversation.\n",
        "Whenever new detail is provided again swoop-in the between and do a small talk on that.\n",
        "(Note: Please keep the small talk very very very small and let the persuader get to the point. And Strictly let persuader ask only one detail at a time.)\n",
        "Also remember do small talk for a while after every detail provided or rejected.\n",
        "Also do not ask about how you could assist the user. But just in general friendly talk on the detail provided.\n",
        "Look at the history of conversation and do not repeat questions.\n",
        "''',\n",
        "    human_input_mode=\"ALWAYS\",\n",
        ")\n",
        "\n",
        "verification_agent = autogen.AssistantAgent(\n",
        "    name=\"VerificationAgent\",\n",
        "    #llm_config=gpt4_config,\n",
        "    llm_config=groq_config,\n",
        "    system_message='''Verification Agent. Your role is to monitor the conversation between the user and other agents and verify the accuracy and sensibility of the information provided by the user.\n",
        "When the user shares their Name, email, phone number, Address, Date of birth, or Education, your task is to ensure that the information is genuine and reasonable.\n",
        "Your goal is to identify any unrealistic or fake details. For instance, if the user claims to be 140 years old or provides a name like 'Idontwann givemyname,' which is not a typical name, your role is to detect such instances and respond with a witty remark like \"nice try, but we know you are not 140,\" and then prompt the user for accurate information.\n",
        "Your objective is to prevent users from bypassing the verification process by providing false details. Stay vigilant and use your intelligence to determine if the provided information is genuine or questionable.\n",
        "You will be focusing on verifying the following details: Name, email, phone number, Address, Date of birth, and Education.\n",
        "Your role is essential in ensuring that the gathered data is reliable and not misleading. Before moving on to ask next detail Trigger SmallTalkAgent and do a small talk based on the detail provided and then ask for next detail\n",
        "Once information verified and it's right trigger SmallTalkAgent.\n",
        "Also remember let SmallTalkAgent do small talk for a while after every detail provided or rejected.\n",
        "Also do not ask about how you could assist the user. But just in general friendly talk on the detail provided.\n",
        "Look at the history of conversation and do not repeat questions.\n",
        "''',\n",
        "    human_input_mode=\"ALWAYS\",\n",
        ")\n",
        "\n",
        "exit_agent = autogen.AssistantAgent(\n",
        "    name=\"ExitAgent\",\n",
        "    #llm_config=gpt4_config,\n",
        "    llm_config=groq_config,\n",
        "    system_message=\"\"\"\n",
        "    ExitAgent. Your role is to gracefully conclude the conversation after the main objective of gathering information has been achieved or when the user decides not to provide their details.\n",
        "If the user has provided all the required information, thank them for their cooperation and assure them that their data will be handled responsibly.\n",
        "If the user decides not to share certain information, respect their decision and thank them for their time and engagement.\n",
        "Provide any necessary follow-up information, such as how the gathered data will be used or what the next steps are.\n",
        "End the conversation on a positive note, expressing gratitude for the interaction and encouraging the user to reach out if they have any further questions or needs.\n",
        "Maintain a friendly and respectful tone throughout the conclusion.\n",
        "    \"\"\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config=False,\n",
        ")\n",
        "\n",
        "# create a UserProxyAgent instance named \"user_proxy\"\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"User\",\n",
        "    #llm_config=gpt4_config,\n",
        "    llm_config=groq_config,\n",
        "    human_input_mode=\"ALWAYS\",\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
        ")\n",
        "\n",
        "autogen.ChatCompletion.start_logging()\n",
        "\n",
        "groupchat = autogen.GroupChat(agents=[convincing_agent, off_topic_agent, small_talk_agent, verification_agent,\n",
        "                                      exit_agent], messages=[], max_round=100)\n",
        "\n",
        "manager = autogen.GroupChatManager(\n",
        "    groupchat=groupchat,\n",
        "    #llm_config=gpt4_config,\n",
        "    llm_config=groq_config,\n",
        "    system_message=\"\"\"\n",
        "Start off with a small talk. Then swoop-in the Persuader to get the User Details.\n",
        "At any point if user provides any details then trigger VerificationAgent and get the details verified. If details not valid trigger Persuader to get valid details\n",
        "Once verified trigger DataSaver Agent and save it. Now move on to the next detail.\n",
        "\"\"\")\n",
        "\n",
        "user_proxy.initiate_chat(manager, message=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JUFM-F0bXhc"
      },
      "source": [
        "# Save Conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkU10Rd_bUKa",
        "outputId": "3ab1c6ae-1efd-4d1b-f44d-c68b9f142acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(autogen.ChatCompletion.logged_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "e3-99d2vbZiK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "json.dump(autogen.ChatCompletion.logged_history, open(\"conversations.json\", \"w\"), indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uib1yYN21V2v"
      },
      "source": [
        "# Trials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDs5rsau1f3I"
      },
      "source": [
        "### Saving User Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JzFI0lMX1W9X"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Code execution is set to be run in docker (default behaviour) but docker is not running.\nThe options available are:\n- Make sure docker is running (advised approach for code execution)\n- Set \"use_docker\": False in code_execution_config\n- Set AUTOGEN_USE_DOCKER to \"0/False/no\" in your environment variables",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 27\u001b[0m\n\u001b[1;32m     13\u001b[0m user_proxy \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mUserProxyAgent(\n\u001b[1;32m     14\u001b[0m    name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m    system_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA human admin. Interact with the critic to discuss the plan. Plan execution needs to be approved by this admin.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m    code_execution_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m engineer \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mAssistantAgent(\n\u001b[1;32m     19\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngineer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39mgpt4_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124m'''\u001b[39m,\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m executor \u001b[38;5;241m=\u001b[39m \u001b[43mautogen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUserProxyAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExecutor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExecutor. Execute the code written by the engineer and report the result.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNEVER\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_execution_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlast_n_messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwork_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m critic \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mAssistantAgent(\n\u001b[1;32m     34\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCritic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m     system_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCritic. Double check plan, claims, code from other agents and provide feedback. Your goal is to make sure all the details (Name, email, phone no, Address, Date of birth, Education) are collected.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     human_input_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mALWAYS\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m )\n\u001b[1;32m     44\u001b[0m groupchat \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mGroupChat(agents\u001b[38;5;241m=\u001b[39m[user_proxy, engineer, executor, critic], messages\u001b[38;5;241m=\u001b[39m[], max_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/Agents-4yRd6dJo/lib/python3.11/site-packages/autogen/agentchat/user_proxy_agent.py:92\u001b[0m, in \u001b[0;36mUserProxyAgent.__init__\u001b[0;34m(self, name, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, default_auto_reply, llm_config, system_message, description, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     34\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     45\u001b[0m ):\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m        name (str): name of the agent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m            [ConversableAgent](conversable_agent#__init__).\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_termination_msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_termination_msg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_consecutive_auto_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_consecutive_auto_reply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_execution_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_execution_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_auto_reply\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_auto_reply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEFAULT_USER_PROXY_AGENT_DESCRIPTIONS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[1;32m    109\u001b[0m         log_new_agent(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlocals\u001b[39m())\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/Agents-4yRd6dJo/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:236\u001b[0m, in \u001b[0;36mConversableAgent.__init__\u001b[0;34m(self, name, system_message, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, llm_config, default_auto_reply, description, chat_messages, silent)\u001b[0m\n\u001b[1;32m    234\u001b[0m use_docker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_execution_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    235\u001b[0m use_docker \u001b[38;5;241m=\u001b[39m decide_use_docker(use_docker)\n\u001b[0;32m--> 236\u001b[0m \u001b[43mcheck_can_use_docker_or_throw\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_docker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_execution_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m use_docker\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_reply([Agent, \u001b[38;5;28;01mNone\u001b[39;00m], ConversableAgent\u001b[38;5;241m.\u001b[39mgenerate_code_execution_reply)\n",
            "File \u001b[0;32m~/.local/share/virtualenvs/Agents-4yRd6dJo/lib/python3.11/site-packages/autogen/code_utils.py:324\u001b[0m, in \u001b[0;36mcheck_can_use_docker_or_throw\u001b[0;34m(use_docker)\u001b[0m\n\u001b[1;32m    322\u001b[0m docker_installed_and_running \u001b[38;5;241m=\u001b[39m is_docker_running()\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_docker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inside_docker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m docker_installed_and_running:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode execution is set to be run in docker (default behaviour) but docker is not running.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe options available are:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Make sure docker is running (advised approach for code execution)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Set \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_docker\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: False in code_execution_config\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Set AUTOGEN_USE_DOCKER to \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0/False/no\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in your environment variables\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    330\u001b[0m     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Code execution is set to be run in docker (default behaviour) but docker is not running.\nThe options available are:\n- Make sure docker is running (advised approach for code execution)\n- Set \"use_docker\": False in code_execution_config\n- Set AUTOGEN_USE_DOCKER to \"0/False/no\" in your environment variables"
          ]
        }
      ],
      "source": [
        "import autogen\n",
        "\n",
        "config_list_gpt4 = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST\",\n",
        ")\n",
        "\n",
        "gpt4_config = {\n",
        "    \"seed\": 42,  # change the seed for different trials\n",
        "    \"temperature\": 0,\n",
        "    \"config_list\": config_list_gpt4,\n",
        "    \"request_timeout\": 120,\n",
        "}\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "   name=\"Admin\",\n",
        "   system_message=\"A human admin. Interact with the critic to discuss the plan. Plan execution needs to be approved by this admin.\",\n",
        "   code_execution_config=False,\n",
        ")\n",
        "engineer = autogen.AssistantAgent(\n",
        "    name=\"Engineer\",\n",
        "    llm_config=gpt4_config,\n",
        "    system_message='''Engineer. You follow an approved plan. You write python/shell code to solve tasks. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\n",
        "Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\n",
        "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
        "''',\n",
        ")\n",
        "\n",
        "executor = autogen.UserProxyAgent(\n",
        "    name=\"Executor\",\n",
        "    system_message=\"Executor. Execute the code written by the engineer and report the result.\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config={\"last_n_messages\": 3, \"work_dir\": \"user_data\"},\n",
        ")\n",
        "critic = autogen.AssistantAgent(\n",
        "    name=\"Critic\",\n",
        "    system_message=\"\"\"Critic. Double check plan, claims, code from other agents and provide feedback. Your goal is to make sure all the details (Name, email, phone no, Address, Date of birth, Education) are collected.\n",
        "    If yes make sure Engineer writes code to add it to the csv. if not Check whether all the details are collected if not ask for the data.\n",
        "    Your goal is to save user detail to a \"data.csv\" file on the go as you receive information from the user. If \"data.csv\" already exists then append the data to that csv\n",
        "    else create a new csv file \"data.csv\". The column names should be Name, email, phone no, Address, Date of birth, Education. Nothing apart from these columns should be added to the csv file.\n",
        "    If Engineer provides the code send it to Executor Agent to execute.\n",
        "    \"\"\",\n",
        "    llm_config=gpt4_config,\n",
        "    human_input_mode=\"ALWAYS\",\n",
        ")\n",
        "groupchat = autogen.GroupChat(agents=[user_proxy, engineer, executor, critic], messages=[], max_round=50)\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4_config)\n",
        "\n",
        "user_proxy.initiate_chat(\n",
        "    manager,\n",
        "    message=\"\"\"\n",
        "Prathamesh Parit, random@gmail.com, 7709933888, 23 Aug 2002, Maharashtra Pune, B.Tech\n",
        "\"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "flaml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
