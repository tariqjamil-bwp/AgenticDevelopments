{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21fa2e13-567d-4509-9023-c99fb230f31f",
   "metadata": {},
   "source": [
    "# Lesson 2 : LangGraph Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9480671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2JWorking directory: </home/tjamil/Desktop/Agents/code_excercises/2.Langgraph/Ai Agents using Langgraph (dl.ai)>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"clear\")\n",
    "abs_path = os.path.dirname(os.path.abspath(__name__))\n",
    "os.chdir(abs_path)\n",
    "print(f\"Working directory: <{os.getcwd()}>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 46
   },
   "outputs": [],
   "source": [
    "#from dotenv import load_dotenv\n",
    "#_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85328c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading environment variables from: </home/tjamil/Desktop/Agents/code_excercises/2.Langgraph/Ai Agents using Langgraph (dl.ai)>\n",
      "API Keys loaded and tracing set with project name:  LangGraph Basics - deeplearning.ai\n"
     ]
    }
   ],
   "source": [
    "from setup_environment_r1 import set_environment_variables\n",
    "set_environment_variables(\"LangGraph Basics - deeplearning.ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137c6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U langchain_groq langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 129
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjamil/.local/share/virtualenvs/Agents-4yRd6dJo/lib/python3.11/site-packages/langchain_community/tools/tavily_search/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_community.tools.tavily_search.tool import (\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "#from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model_name=\"llama3-groq-70b-8192-tool-use-preview\", api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 78
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=4) #increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)   # this is the name of the tool taht will be used by LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196c186-af55-4f2d-b569-b7d63a859304",
   "metadata": {},
   "source": [
    "> If you are not familiar with python typing annotation, you can refer to the [python documents](https://docs.python.org/3/library/typing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7ba73-e603-453b-b06f-5db92c567b19",
   "metadata": {},
   "source": [
    "> Note: in `take_action` below, some logic was added to cover the case that the LLM returned a non-existent tool name. Even with function calling, LLMs can still occasionally hallucinate. Note that all that is done is instructing the LLM to try again! An advantage of an agentic organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 741
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        #setting up the system message\n",
    "        self.system = system\n",
    "        \n",
    "        #defining the graph\n",
    "        graph = StateGraph(AgentState)\n",
    "        \n",
    "        #adding nodes (llm, action/tools)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        \n",
    "        #adding conditional edges (decide if action should be taken or not, and which node to go to)\n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "        \n",
    "        #adding edges\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        \n",
    "        #setting entry point\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        \n",
    "        #compiling the graph (creates a runnable graph)\n",
    "        self.graph = graph.compile()\n",
    "        \n",
    "        #defining the tools\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        \n",
    "        #defining the model with tools binding\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    #defining the function for conditional edge \n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    #defining 'llm node' function\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    #defining 'action node' function\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls    \n",
    "        # .too_call is attribute returned aalongside message by functiona calling llms\n",
    "        \n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            if not t['name'] in self.tools:      # check for bad tool name from LLM\n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"bad tool name, retry\"  # instruct LLM to retry if bad\n",
    "            else:\n",
    "                result = self.tools[t['name']].invoke(t['args'])\n",
    "                print(f\"Result: {result}\")\n",
    "\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        \n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 163
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "#model = ChatOpenAI(model=\"gpt-3.5-turbo\")  #reduce inference cost\n",
    "abot = Agent(model, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d6f5f4-2392-41b9-ab96-7919840baa3e",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "#Image(abot.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 61
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_pvyb', 'type': 'tool_call'}\n",
      "Result: AttributeError(\"'FieldInfo' object has no attribute 'results'\")\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'weather forecast for San Francisco'}, 'id': 'call_decn', 'type': 'tool_call'}\n",
      "Result: AttributeError(\"'FieldInfo' object has no attribute 'results'\")\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?. Give just suffiucient information.\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a06a8c-fcd4-4ca6-98f0-36c5809813e6",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in sf?. Give just suffiucient information.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_pvyb', 'function': {'arguments': '{\"query\": \"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_decn', 'function': {'arguments': '{\"query\": \"weather forecast for San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 301, 'total_tokens': 369, 'completion_time': 0.214783729, 'prompt_time': 0.02229261, 'queue_time': 0.010779118, 'total_time': 0.237076339}, 'model_name': 'llama3-groq-70b-8192-tool-use-preview', 'system_fingerprint': 'fp_ee4b521143', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d149e7e0-0f46-4283-85b9-f1b769c67ee9-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_pvyb', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'weather forecast for San Francisco'}, 'id': 'call_decn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 301, 'output_tokens': 68, 'total_tokens': 369}),\n",
       "  ToolMessage(content='AttributeError(\"\\'FieldInfo\\' object has no attribute \\'results\\'\")', name='tavily_search_results_json', tool_call_id='call_pvyb'),\n",
       "  ToolMessage(content='AttributeError(\"\\'FieldInfo\\' object has no attribute \\'results\\'\")', name='tavily_search_results_json', tool_call_id='call_decn'),\n",
       "  AIMessage(content=\"I'm sorry, I encountered an error while retrieving the weather information for San Francisco. Could you please provide me with a different query or more details about what you're looking for?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 429, 'total_tokens': 466, 'completion_time': 0.11558722, 'prompt_time': 0.029653296, 'queue_time': 0.0036822900000000013, 'total_time': 0.145240516}, 'model_name': 'llama3-groq-70b-8192-tool-use-preview', 'system_fingerprint': 'fp_ee4b521143', 'finish_reason': 'stop', 'logprobs': None}, id='run-3d430282-beef-4234-93ad-03843836ca75-0', usage_metadata={'input_tokens': 429, 'output_tokens': 37, 'total_tokens': 466})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I encountered an error while retrieving the weather information for San Francisco. Could you please provide me with a different query or more details about what you're looking for?\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 61
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_j2qm', 'type': 'tool_call'}\n",
      "Result: AttributeError(\"'FieldInfo' object has no attribute 'results'\")\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_5be4', 'type': 'tool_call'}\n",
      "Result: AttributeError(\"'FieldInfo' object has no attribute 'results'\")\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF and LA?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I encountered an error while trying to retrieve the weather information for San Francisco and Los Angeles. It seems like there's an issue with the search engine I'm using.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 197
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'who won the super bowl in 2024'}, 'id': 'call_22hf', 'type': 'tool_call'}\n",
      "Result: AttributeError(\"'FieldInfo' object has no attribute 'results'\")\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'headquarters location of the winning team'}, 'id': 'call_q6ww', 'type': 'tool_call'}\n",
      "Result: AttributeError(\"'FieldInfo' object has no attribute 'results'\")\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': \"GDP of the state where the winning team's headquarters is located\"}, 'id': 'call_fwdd', 'type': 'tool_call'}\n",
      "Result: AttributeError(\"'FieldInfo' object has no attribute 'results'\")\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "# Note, the query was modified to produce more consistent results. \n",
    "# Results may vary per run and over time as search information and models change.\n",
    "\n",
    "query = \"Who won the super bowl in 2024? In what state is the winning team headquarters located? \\\n",
    "What is the GDP of that state? Answer each question.\" \n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "#model = ChatOpenAI(model=\"gpt-4o\")  # requires more advanced model\n",
    "abot = Agent(model, [tool], system=prompt)\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I encountered an error while searching for the information you requested. It seems like there was a problem with the search engine. I'll need to try a different method to find the answers to your questions.\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agents-4yRd6dJo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
