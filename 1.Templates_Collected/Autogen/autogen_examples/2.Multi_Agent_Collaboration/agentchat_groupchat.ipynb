{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTfy_E_z1F34"
      },
      "source": [
        "# Group Chat\n",
        "\n",
        "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
        "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
        "\n",
        "This notebook is modified based on https://github.com/microsoft/FLAML/blob/4ea686af5c3e8ff24d9076a7a626c8b28ab5b1d7/notebook/autogen_multiagent_roleplay_chat.ipynb\n",
        "\n",
        "````{=mdx}\n",
        ":::info Requirements\n",
        "Install `pyautogen`:\n",
        "```bash\n",
        "pip install pyautogen\n",
        "```\n",
        "\n",
        "For more information, please refer to the [installation guide](/docs/installation/).\n",
        ":::\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDobkzb81F4A"
      },
      "source": [
        "## Set your API Endpoint\n",
        "\n",
        "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W7GN3alC1F4B"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'config_list = autogen.config_list_from_json(\\n    \"OAI_CONFIG_LIST\",\\n    filter_dict={\\n        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\\n    },\\n)'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import autogen\n",
        "\n",
        "'''config_list = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST\",\n",
        "    filter_dict={\n",
        "        \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
        "    },\n",
        ")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "config_list = [\n",
        "    {\"api_type\": \"groq\", \"model\": \"llama-3.1-70b-versatile\", \"api_key\": os.environ.get(\"GROQ_API_KEY\")},\n",
        "    {\"api_type\": \"groq\", \"model\": \"llama3-70b-8192\", \"api_key\": os.environ.get(\"GROQ_API_KEY\")},\n",
        "    {\"api_type\": \"groq\", \"model\": \"llama3-groq-70b-8192-tool-use-preview\", \"api_key\": os.environ.get(\"GROQ_API_KEY\")},\n",
        "    {\"api_type\": \"groq\", \"model\": \"mixtral-8x7b-32768\", \"api_key\": os.environ.get(\"GROQ_API_KEY\")},\n",
        "    {\"api_type\": \"groq\", \"model\": \"llama3-groq-8b-8192-tool-use-preview\", \"api_key\": os.environ.get(\"GROQ_API_KEY\")},\n",
        "    {\"api_type\": \"groq\", \"model\": \"gemma2-9b-it\", \"api_key\": os.environ.get(\"GROQ_API_KEY\")},\n",
        "    {\"api_type\": \"groq\", \"model\": \"llama-3.1-8b-instant\", \"api_key\": os.environ.get(\"GROQ_API_KEY\")},\n",
        "    {\"api_type\": \"groq\", \"model\": \"llama-guard-3-8b\", \"api_key\": os.environ.get(\"GROQ_API_KEY\")},\n",
        "    {\"api_type\": \"groq\", \"model\": \"llama3-8b-8192\", \"api_key\": os.environ.get(\"GROQ_API_KEY\")},\n",
        "    ]\n",
        "\n",
        "llm_config={\"config_list\" : config_list}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3tjUvec1F4D"
      },
      "source": [
        "````{=mdx}\n",
        ":::tip\n",
        "Learn more about configuring LLMs for agents [here](/docs/topics/llm_configuration).\n",
        ":::\n",
        "````\n",
        "\n",
        "## Construct Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZOsi7v3S1F4D"
      },
      "outputs": [],
      "source": [
        "llm_config = {\"config_list\": config_list, \"cache_seed\": 42}\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"User_proxy\",\n",
        "    system_message=\"A human admin.\",\n",
        "    code_execution_config={\n",
        "        \"last_n_messages\": 2,\n",
        "        \"work_dir\": \"groupchat\",\n",
        "        \"use_docker\": False,\n",
        "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
        "    human_input_mode=\"TERMINATE\",\n",
        ")\n",
        "coder = autogen.AssistantAgent(\n",
        "    name=\"Coder\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "pm = autogen.AssistantAgent(\n",
        "    name=\"Product_manager\",\n",
        "    system_message=\"Creative in software product ideas.\",\n",
        "    llm_config=llm_config,\n",
        ")\n",
        "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJa5_6jf1F4E"
      },
      "source": [
        "## Start Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fpv4wK9R1F4E",
        "outputId": "b92d2e4d-3f2b-4d85-d28f-db2280ca903b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
            "\n",
            "Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[32m\n",
            "Next speaker: User_proxy\n",
            "\u001b[0m\n",
            "\u001b[31m\n",
            ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
            "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tjamil/.local/share/virtualenvs/Agents-4yRd6dJo/lib/python3.11/site-packages/autogen/oai/groq.py:286: UserWarning: Cost calculation not available for model llama-3.1-70b-versatile\n",
            "  warnings.warn(f\"Cost calculation not available for model {model}\", UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m\n",
            "Next speaker: Coder\n",
            "\u001b[0m\n",
            "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
            "\n",
            "To find the latest paper about GPT-4 on arxiv, we will use the arxiv API to search for papers. First, let's write a python script to search for papers about GPT-4.\n",
            "\n",
            "```python\n",
            "# filename: search_gpt4.py\n",
            "import requests\n",
            "\n",
            "def search_arxiv(query):\n",
            "    url = f\"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results=10\"\n",
            "    response = requests.get(url)\n",
            "    if response.status_code == 200:\n",
            "        return response.text\n",
            "    else:\n",
            "        return None\n",
            "\n",
            "gpt4_query = \"GPT-4\"\n",
            "result = search_arxiv(gpt4_query)\n",
            "print(result)\n",
            "```\n",
            "\n",
            "Please execute this script. Once you execute the script and return the result, I will parse the result to find the latest paper about GPT-4. Then, I will analyze the paper to find its potential applications in software.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[32m\n",
            "Next speaker: User_proxy\n",
            "\u001b[0m\n",
            "\u001b[31m\n",
            ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
            "\u001b[31m\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
            "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
            "\n",
            "exitcode: 0 (execution succeeded)\n",
            "Code output: \n",
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
            "  <link href=\"http://arxiv.org/api/query?search_query%3Dall%3AGPT-4%26id_list%3D%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\n",
            "  <title type=\"html\">ArXiv Query: search_query=all:GPT-4&amp;id_list=&amp;start=0&amp;max_results=10</title>\n",
            "  <id>http://arxiv.org/api/pLT/OU6tmcNhPiDL3bDBU6TeCQY</id>\n",
            "  <updated>2024-09-25T00:00:00-04:00</updated>\n",
            "  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">2460</opensearch:totalResults>\n",
            "  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n",
            "  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\n",
            "  <entry>\n",
            "    <id>http://arxiv.org/abs/2407.08969v1</id>\n",
            "    <updated>2024-07-12T03:33:13Z</updated>\n",
            "    <published>2024-07-12T03:33:13Z</published>\n",
            "    <title>Detect Llama -- Finding Vulnerabilities in Smart Contracts using Large\n",
            "  Language Models</title>\n",
            "    <summary>  In this paper, we test the hypothesis that although OpenAI's GPT-4 performs\n",
            "well generally, we can fine-tune open-source models to outperform GPT-4 in\n",
            "smart contract vulnerability detection. We fine-tune two models from Meta's\n",
            "Code Llama and a dataset of 17k prompts, Detect Llama - Foundation and Detect\n",
            "Llama - Instruct, and we also fine-tune OpenAI's GPT-3.5 Turbo model\n",
            "(GPT-3.5FT). We then evaluate these models, plus a random baseline, on a\n",
            "testset we develop against GPT-4, and GPT-4 Turbo's, detection of eight\n",
            "vulnerabilities from the dataset and the two top identified vulnerabilities -\n",
            "and their weighted F1 scores.\n",
            "  We find that for binary classification (i.e., is this smart contract\n",
            "vulnerable?), our two best-performing models, GPT-3.5FT and Detect Llama -\n",
            "Foundation, achieve F1 scores of $0.776$ and $0.68$, outperforming both GPT-4\n",
            "and GPT-4 Turbo, $0.66$ and $0.675$. For the evaluation against individual\n",
            "vulnerability identification, our top two models, GPT-3.5FT and Detect Llama -\n",
            "Foundation, both significantly outperformed GPT-4 and GPT-4 Turbo in both\n",
            "weighted F1 for all vulnerabilities ($0.61$ and $0.56$ respectively against\n",
            "GPT-4's $0.218$ and GPT-4 Turbo's $0.243$) and weighted F1 for the top two\n",
            "identified vulnerabilities ($0.719$ for GPT-3.5FT, $0.674$ for Detect Llama -\n",
            "Foundation against GPT-4's $0.363$ and GPT-4 Turbo's $0.429$).\n",
            "</summary>\n",
            "    <author>\n",
            "      <name>Peter Ince</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Xiapu Luo</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Jiangshan Yu</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Joseph K. Liu</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Xiaoning Du</name>\n",
            "    </author>\n",
            "    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.1007/978-981-97-5101-3_23</arxiv:doi>\n",
            "    <link title=\"doi\" href=\"http://dx.doi.org/10.1007/978-981-97-5101-3_23\" rel=\"related\"/>\n",
            "    <link href=\"http://arxiv.org/abs/2407.08969v1\" rel=\"alternate\" type=\"text/html\"/>\n",
            "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2407.08969v1\" rel=\"related\" type=\"application/pdf\"/>\n",
            "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CR\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "  </entry>\n",
            "  <entry>\n",
            "    <id>http://arxiv.org/abs/2306.01499v1</id>\n",
            "    <updated>2023-06-02T12:47:45Z</updated>\n",
            "    <published>2023-06-02T12:47:45Z</published>\n",
            "    <title>Can LLMs like GPT-4 outperform traditional AI tools in dementia\n",
            "  diagnosis? Maybe, but not today</title>\n",
            "    <summary>  Recent investigations show that large language models (LLMs), specifically\n",
            "GPT-4, not only have remarkable capabilities in common Natural Language\n",
            "Processing (NLP) tasks but also exhibit human-level performance on various\n",
            "professional and academic benchmarks. However, whether GPT-4 can be directly\n",
            "used in practical applications and replace traditional artificial intelligence\n",
            "(AI) tools in specialized domains requires further experimental validation. In\n",
            "this paper, we explore the potential of LLMs such as GPT-4 to outperform\n",
            "traditional AI tools in dementia diagnosis. Comprehensive comparisons between\n",
            "GPT-4 and traditional AI tools are conducted to examine their diagnostic\n",
            "accuracy in a clinical setting. Experimental results on two real clinical\n",
            "datasets show that, although LLMs like GPT-4 demonstrate potential for future\n",
            "advancements in dementia diagnosis, they currently do not surpass the\n",
            "performance of traditional AI tools. The interpretability and faithfulness of\n",
            "GPT-4 are also evaluated by comparison with real doctors. We discuss the\n",
            "limitations of GPT-4 in its current state and propose future research\n",
            "directions to enhance GPT-4 in dementia diagnosis.\n",
            "</summary>\n",
            "    <author>\n",
            "      <name>Zhuo Wang</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Rongzhen Li</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Bowen Dong</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Jie Wang</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Xiuxing Li</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Ning Liu</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Chenhui Mao</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Wei Zhang</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Liling Dong</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Jing Gao</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Jianyong Wang</name>\n",
            "    </author>\n",
            "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">16 pages, 6 figures</arxiv:comment>\n",
            "    <link href=\"http://arxiv.org/abs/2306.01499v1\" rel=\"alternate\" type=\"text/html\"/>\n",
            "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2306.01499v1\" rel=\"related\" type=\"application/pdf\"/>\n",
            "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "  </entry>\n",
            "  <entry>\n",
            "    <id>http://arxiv.org/abs/2308.03762v2</id>\n",
            "    <updated>2023-08-10T14:24:37Z</updated>\n",
            "    <published>2023-07-21T17:04:25Z</published>\n",
            "    <title>GPT-4 Can't Reason</title>\n",
            "    <summary>  GPT-4 was released in March 2023 to wide acclaim, marking a very substantial\n",
            "improvement across the board over GPT-3.5 (OpenAI's previously best model,\n",
            "which had powered the initial release of ChatGPT). However, despite the\n",
            "genuinely impressive improvement, there are good reasons to be highly skeptical\n",
            "of GPT-4's ability to reason. This position paper discusses the nature of\n",
            "reasoning; criticizes the current formulation of reasoning problems in the NLP\n",
            "community, as well as the way in which LLM reasoning performance is currently\n",
            "evaluated; introduces a small collection of 21 diverse reasoning problems; and\n",
            "performs a detailed qualitative evaluation of GPT-4's performance on those\n",
            "problems. Based on this analysis, the paper concludes that, despite its\n",
            "occasional flashes of analytical brilliance, GPT-4 at present is utterly\n",
            "incapable of reasoning.\n",
            "</summary>\n",
            "    <author>\n",
            "      <name>Konstantine Arkoudas</name>\n",
            "    </author>\n",
            "    <link href=\"http://arxiv.org/abs/2308.03762v2\" rel=\"alternate\" type=\"text/html\"/>\n",
            "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2308.03762v2\" rel=\"related\" type=\"application/pdf\"/>\n",
            "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "  </entry>\n",
            "  <entry>\n",
            "    <id>http://arxiv.org/abs/2304.03439v3</id>\n",
            "    <updated>2023-05-05T07:24:48Z</updated>\n",
            "    <published>2023-04-07T01:37:45Z</published>\n",
            "    <title>Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4</title>\n",
            "    <summary>  Harnessing logical reasoning ability is a comprehensive natural language\n",
            "understanding endeavor. With the release of Generative Pretrained Transformer 4\n",
            "(GPT-4), highlighted as \"advanced\" at reasoning tasks, we are eager to learn\n",
            "the GPT-4 performance on various logical reasoning tasks. This report analyses\n",
            "multiple logical reasoning datasets, with popular benchmarks like LogiQA and\n",
            "ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice\n",
            "reading comprehension and natural language inference tasks with benchmarks\n",
            "requiring logical reasoning. We further construct a logical reasoning\n",
            "out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4.\n",
            "We also make a performance comparison between ChatGPT and GPT-4. Experiment\n",
            "results show that ChatGPT performs significantly better than the RoBERTa\n",
            "fine-tuning method on most logical reasoning benchmarks. With early access to\n",
            "the GPT-4 API we are able to conduct intense experiments on the GPT-4 model.\n",
            "The results show GPT-4 yields even higher performance on most logical reasoning\n",
            "datasets. Among benchmarks, ChatGPT and GPT-4 do relatively well on well-known\n",
            "datasets like LogiQA and ReClor. However, the performance drops significantly\n",
            "when handling newly released and out-of-distribution datasets. Logical\n",
            "reasoning remains challenging for ChatGPT and GPT-4, especially on\n",
            "out-of-distribution and natural language inference datasets. We release the\n",
            "prompt-style logical reasoning datasets as a benchmark suite and name it\n",
            "LogiEval.\n",
            "</summary>\n",
            "    <author>\n",
            "      <name>Hanmeng Liu</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Ruoxi Ning</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Zhiyang Teng</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Jian Liu</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Qiji Zhou</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Yue Zhang</name>\n",
            "    </author>\n",
            "    <link href=\"http://arxiv.org/abs/2304.03439v3\" rel=\"alternate\" type=\"text/html\"/>\n",
            "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2304.03439v3\" rel=\"related\" type=\"application/pdf\"/>\n",
            "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "  </entry>\n",
            "  <entry>\n",
            "    <id>http://arxiv.org/abs/2307.09009v3</id>\n",
            "    <updated>2023-10-31T16:13:44Z</updated>\n",
            "    <published>2023-07-18T06:56:08Z</published>\n",
            "    <title>How is ChatGPT's behavior changing over time?</title>\n",
            "    <summary>  GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\n",
            "services. However, when and how these models are updated over time is opaque.\n",
            "Here, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\n",
            "several diverse tasks: 1) math problems, 2) sensitive/dangerous questions, 3)\n",
            "opinion surveys, 4) multi-hop knowledge-intensive questions, 5) generating\n",
            "code, 6) US Medical License tests, and 7) visual reasoning. We find that the\n",
            "performance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.\n",
            "For example, GPT-4 (March 2023) was reasonable at identifying prime vs.\n",
            "composite numbers (84% accuracy) but GPT-4 (June 2023) was poor on these same\n",
            "questions (51% accuracy). This is partly explained by a drop in GPT-4's amenity\n",
            "to follow chain-of-thought prompting. Interestingly, GPT-3.5 was much better in\n",
            "June than in March in this task. GPT-4 became less willing to answer sensitive\n",
            "questions and opinion survey questions in June than in March. GPT-4 performed\n",
            "better at multi-hop questions in June than in March, while GPT-3.5's\n",
            "performance dropped on this task. Both GPT-4 and GPT-3.5 had more formatting\n",
            "mistakes in code generation in June than in March. We provide evidence that\n",
            "GPT-4's ability to follow user instructions has decreased over time, which is\n",
            "one common factor behind the many behavior drifts. Overall, our findings show\n",
            "that the behavior of the \"same\" LLM service can change substantially in a\n",
            "relatively short amount of time, highlighting the need for continuous\n",
            "monitoring of LLMs.\n",
            "</summary>\n",
            "    <author>\n",
            "      <name>Lingjiao Chen</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Matei Zaharia</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>James Zou</name>\n",
            "    </author>\n",
            "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">add more evaluations on instruction following</arxiv:comment>\n",
            "    <link href=\"http://arxiv.org/abs/2307.09009v3\" rel=\"alternate\" type=\"text/html\"/>\n",
            "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2307.09009v3\" rel=\"related\" type=\"application/pdf\"/>\n",
            "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "  </entry>\n",
            "  <entry>\n",
            "    <id>http://arxiv.org/abs/2305.03195v1</id>\n",
            "    <updated>2023-05-04T22:46:43Z</updated>\n",
            "    <published>2023-05-04T22:46:43Z</published>\n",
            "    <title>Gpt-4: A Review on Advancements and Opportunities in Natural Language\n",
            "  Processing</title>\n",
            "    <summary>  Generative Pre-trained Transformer 4 (GPT-4) is the fourth-generation\n",
            "language model in the GPT series, developed by OpenAI, which promises\n",
            "significant advancements in the field of natural language processing (NLP). In\n",
            "this research article, we have discussed the features of GPT-4, its potential\n",
            "applications, and the challenges that it might face. We have also compared\n",
            "GPT-4 with its predecessor, GPT-3. GPT-4 has a larger model size (more than one\n",
            "trillion), better multilingual capabilities, improved contextual understanding,\n",
            "and reasoning capabilities than GPT-3. Some of the potential applications of\n",
            "GPT-4 include chatbots, personal assistants, language translation, text\n",
            "summarization, and question-answering. However, GPT-4 poses several challenges\n",
            "and limitations such as computational requirements, data requirements, and\n",
            "ethical concerns.\n",
            "</summary>\n",
            "    <author>\n",
            "      <name>Jawid Ahmad Baktash</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Mursal Dawodi</name>\n",
            "    </author>\n",
            "    <link href=\"http://arxiv.org/abs/2305.03195v1\" rel=\"alternate\" type=\"text/html\"/>\n",
            "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2305.03195v1\" rel=\"related\" type=\"application/pdf\"/>\n",
            "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "  </entry>\n",
            "  <entry>\n",
            "    <id>http://arxiv.org/abs/2305.15038v2</id>\n",
            "    <updated>2023-10-23T02:10:58Z</updated>\n",
            "    <published>2023-05-24T11:26:59Z</published>\n",
            "    <title>Is GPT-4 a Good Data Analyst?</title>\n",
            "    <summary>  As large language models (LLMs) have demonstrated their powerful capabilities\n",
            "in plenty of domains and tasks, including context understanding, code\n",
            "generation, language generation, data storytelling, etc., many data analysts\n",
            "may raise concerns if their jobs will be replaced by artificial intelligence\n",
            "(AI). This controversial topic has drawn great attention in public. However, we\n",
            "are still at a stage of divergent opinions without any definitive conclusion.\n",
            "Motivated by this, we raise the research question of \"is GPT-4 a good data\n",
            "analyst?\" in this work and aim to answer it by conducting head-to-head\n",
            "comparative studies. In detail, we regard GPT-4 as a data analyst to perform\n",
            "end-to-end data analysis with databases from a wide range of domains. We\n",
            "propose a framework to tackle the problems by carefully designing the prompts\n",
            "for GPT-4 to conduct experiments. We also design several task-specific\n",
            "evaluation metrics to systematically compare the performance between several\n",
            "professional human data analysts and GPT-4. Experimental results show that\n",
            "GPT-4 can achieve comparable performance to humans. We also provide in-depth\n",
            "discussions about our results to shed light on further studies before reaching\n",
            "the conclusion that GPT-4 can replace data analysts.\n",
            "</summary>\n",
            "    <author>\n",
            "      <name>Liying Cheng</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Xingxuan Li</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Lidong Bing</name>\n",
            "    </author>\n",
            "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">19 pages, 2 figures</arxiv:comment>\n",
            "    <link href=\"http://arxiv.org/abs/2305.15038v2\" rel=\"alternate\" type=\"text/html\"/>\n",
            "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2305.15038v2\" rel=\"related\" type=\"application/pdf\"/>\n",
            "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "  </entry>\n",
            "  <entry>\n",
            "    <id>http://arxiv.org/abs/2310.01436v2</id>\n",
            "    <updated>2024-03-14T11:50:51Z</updated>\n",
            "    <published>2023-09-30T08:05:59Z</published>\n",
            "    <title>Graph Neural Architecture Search with GPT-4</title>\n",
            "    <summary>  Graph Neural Architecture Search (GNAS) has shown promising results in\n",
            "automatically designing graph neural networks. However, GNAS still requires\n",
            "intensive human labor with rich domain knowledge to design the search space and\n",
            "search strategy. In this paper, we integrate GPT-4 into GNAS and propose a new\n",
            "GPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The\n",
            "basic idea of our method is to design a new class of prompts for GPT-4 to guide\n",
            "GPT-4 toward the generative task of graph neural architectures. The prompts\n",
            "consist of descriptions of the search space, search strategy, and search\n",
            "feedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS\n",
            "generates more accurate graph neural networks with fast convergence.\n",
            "Experimental results show that embedding GPT-4 into GNAS outperforms the\n",
            "state-of-the-art GNAS methods.\n",
            "</summary>\n",
            "    <author>\n",
            "      <name>Haishuai Wang</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Yang Gao</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Xin Zheng</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Peng Zhang</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Hongyang Chen</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Jiajun Bu</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Philip S. Yu</name>\n",
            "    </author>\n",
            "    <link href=\"http://arxiv.org/abs/2310.01436v2\" rel=\"alternate\" type=\"text/html\"/>\n",
            "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2310.01436v2\" rel=\"related\" type=\"application/pdf\"/>\n",
            "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "  </entry>\n",
            "  <entry>\n",
            "    <id>http://arxiv.org/abs/2407.14344v1</id>\n",
            "    <updated>2024-07-19T14:28:07Z</updated>\n",
            "    <published>2024-07-19T14:28:07Z</published>\n",
            "    <title>LLMs left, right, and center: Assessing GPT's capabilities to label\n",
            "  political bias from web domains</title>\n",
            "    <summary>  This research investigates whether OpenAI's GPT-4, a state-of-the-art large\n",
            "language model, can accurately classify the political bias of news sources\n",
            "based solely on their URLs. Given the subjective nature of political labels,\n",
            "third-party bias ratings like those from Ad Fontes Media, AllSides, and Media\n",
            "Bias/Fact Check (MBFC) are often used in research to analyze news source\n",
            "diversity. This study aims to determine if GPT-4 can replicate these human\n",
            "ratings on a seven-degree scale (\"far-left\" to \"far-right\"). The analysis\n",
            "compares GPT-4's classifications against MBFC's, and controls for website\n",
            "popularity using Open PageRank scores. Findings reveal a high correlation\n",
            "($\\text{Spearman's } \\rho = .89$, $n = 5,877$, $p &lt; 0.001$) between GPT-4's and\n",
            "MBFC's ratings, indicating the model's potential reliability. However, GPT-4\n",
            "abstained from classifying approximately $\\frac{2}{3}$ of the dataset,\n",
            "particularly less popular and less biased sources. The study also identifies a\n",
            "slight leftward skew in GPT-4's classifications compared to MBFC's. The\n",
            "analysis suggests that while GPT-4 can be a scalable, cost-effective tool for\n",
            "political bias classification of news websites, but its use should complement\n",
            "human judgment to mitigate biases. Further research is recommended to explore\n",
            "the model's performance across different settings, languages, and additional\n",
            "datasets.\n",
            "</summary>\n",
            "    <author>\n",
            "      <name>Raphael Hernandes</name>\n",
            "    </author>\n",
            "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">12 pages, 4 figures</arxiv:comment>\n",
            "    <link href=\"http://arxiv.org/abs/2407.14344v1\" rel=\"alternate\" type=\"text/html\"/>\n",
            "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2407.14344v1\" rel=\"related\" type=\"application/pdf\"/>\n",
            "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CY\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "  </entry>\n",
            "  <entry>\n",
            "    <id>http://arxiv.org/abs/2308.07921v1</id>\n",
            "    <updated>2023-08-15T17:58:45Z</updated>\n",
            "    <published>2023-08-15T17:58:45Z</published>\n",
            "    <title>Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with\n",
            "  Code-based Self-Verification</title>\n",
            "    <summary>  Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has\n",
            "brought significant advancements in addressing math reasoning problems. In\n",
            "particular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter,\n",
            "shows remarkable performance on challenging math datasets. In this paper, we\n",
            "explore the effect of code on enhancing LLMs' reasoning capability by\n",
            "introducing different constraints on the \\textit{Code Usage Frequency} of GPT-4\n",
            "Code Interpreter. We found that its success can be largely attributed to its\n",
            "powerful skills in generating and executing code, evaluating the output of code\n",
            "execution, and rectifying its solution when receiving unreasonable outputs.\n",
            "Based on this insight, we propose a novel and effective prompting method,\n",
            "explicit \\uline{c}ode-based \\uline{s}elf-\\uline{v}erification~(CSV), to further\n",
            "boost the mathematical reasoning potential of GPT-4 Code Interpreter. This\n",
            "method employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to\n",
            "use code to self-verify its answers. In instances where the verification state\n",
            "registers as ``False'', the model shall automatically amend its solution,\n",
            "analogous to our approach of rectifying errors during a mathematics\n",
            "examination. Furthermore, we recognize that the states of the verification\n",
            "result indicate the confidence of a solution, which can improve the\n",
            "effectiveness of majority voting. With GPT-4 Code Interpreter and CSV, we\n",
            "achieve an impressive zero-shot accuracy on MATH dataset \\textbf{(53.9\\% $\\to$\n",
            "84.3\\%)}.\n",
            "</summary>\n",
            "    <author>\n",
            "      <name>Aojun Zhou</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Ke Wang</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Zimu Lu</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Weikang Shi</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Sichun Luo</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Zipeng Qin</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Shaoqing Lu</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Anya Jia</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Linqi Song</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Mingjie Zhan</name>\n",
            "    </author>\n",
            "    <author>\n",
            "      <name>Hongsheng Li</name>\n",
            "    </author>\n",
            "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Solving Challenging Math Word Problems Using GPT-4 Code Interpreter\n",
            "  with Code-based Self-Verification</arxiv:comment>\n",
            "    <link href=\"http://arxiv.org/abs/2308.07921v1\" rel=\"alternate\" type=\"text/html\"/>\n",
            "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2308.07921v1\" rel=\"related\" type=\"application/pdf\"/>\n",
            "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "    <category term=\"cs.CV\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
            "  </entry>\n",
            "</feed>\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[32m\n",
            "Next speaker: Coder\n",
            "\u001b[0m\n",
            "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
            "\n",
            "Based on the arxiv API result, the latest paper about GPT-4 is \"GPT-4: A Review on Advancements and Opportunities in Natural Language Processing\" (http://arxiv.org/abs/2305.03195v1).\n",
            "\n",
            "According to this paper, GPT-4 is the fourth-generation language model in the GPT series, developed by OpenAI, which promises significant advancements in the field of natural language processing (NLP). The paper discusses the features of GPT-4, its potential applications, and the challenges that it might face. The authors also compare GPT-4 with its predecessor, GPT-3, and highlight its larger model size, better multilingual capabilities, improved contextual understanding, and reasoning capabilities.\n",
            "\n",
            "The potential applications of GPT-4 mentioned in the paper include:\n",
            "\n",
            "* Chatbots\n",
            "* Personal assistants\n",
            "* Language translation\n",
            "* Text summarization\n",
            "* Question-answering\n",
            "\n",
            "However, the paper also poses several challenges and limitations of GPT-4, such as computational requirements, data requirements, and ethical concerns.\n",
            "\n",
            "In addition to this paper, other arxiv papers listed in the API result also explored various applications of GPT-4 in software, such as:\n",
            "\n",
            "* Detecting vulnerabilities in smart contracts\n",
            "* Dementia diagnosis\n",
            "* Logical reasoning\n",
            "* Data analysis\n",
            "* Graph neural architecture search\n",
            "* Political bias classification\n",
            "* Solving math word problems\n",
            "\n",
            "These papers demonstrate the versatility and potential of GPT-4 in a wide range of applications, from natural language processing to software development and data analysis.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[32m\n",
            "Next speaker: Coder\n",
            "\u001b[0m\n",
            "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[32m\n",
            "Next speaker: Coder\n",
            "\u001b[0m\n",
            "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
            "\n",
            "Based on the arxiv API result, another paper \"Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification\" (http://arxiv.org/abs/2308.07921v1) is more closely related to software, specifically, using GPT-4 for math reasoning and solving challenging math word problems.\n",
            "\n",
            "This paper explores the use of GPT-4 Code Interpreter, a version of GPT-4 that is capable of generating and executing code, to solve math word problems. The authors propose a novel prompting method, explicit code-based self-verification (CSV), to further boost the mathematical reasoning potential of GPT-4 Code Interpreter. This method employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to use code to self-verify its answers.\n",
            "\n",
            "The authors found that GPT-4 Code Interpreter with CSV achieves impressive zero-shot accuracy on the MATH dataset, with an accuracy of 84.3% compared to 53.9% without CSV.\n",
            "\n",
            "This paper demonstrates the potential of GPT-4 in software development, specifically in the area of math reasoning and problem-solving. It highlights the capabilities of GPT-4 Code Interpreter in generating and executing code, as well as its ability to self-verify its answers using code-based methods.\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[32m\n",
            "Next speaker: Product_manager\n",
            "\u001b[0m\n",
            "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
            "\n",
            "**Potential Applications and Opportunities in Software**\n",
            "\n",
            "1. **Math Reasoning and Problem-Solving**: GPT-4 Code Interpreter can be used to solve math word problems, making it a valuable tool for education, research, and industry.\n",
            "2. **Automated Code Generation**: GPT-4's ability to generate and execute code can be leveraged to automate code generation tasks, such as coding interviews, software testing, and code review.\n",
            "3. **Self-Verification and Debugging**: The explicit code-based self-verification (CSV) method proposed in the paper can be applied to improve the accuracy of GPT-4 Code Interpreter and other AI-powered code generation tools.\n",
            "4. **Machine Learning and AI**: GPT-4 can be used as a building block for more advanced AI models, such as those that integrate natural language processing and computer vision.\n",
            "5. **Computer-Assisted Learning**: GPT-4 can be integrated into educational software to provide personalized learning experiences for students, helping them to improve their math skills and problem-solving abilities.\n",
            "\n",
            "**Future Research Directions**\n",
            "\n",
            "1. **Improving GPT-4 Code Interpreter**: Research can focus on improving the accuracy, efficiency, and robustness of GPT-4 Code Interpreter, as well as exploring its applications in various software development tasks.\n",
            "2. **Integrating GPT-4 with Other AI Models**: Researchers can investigate the potential of integrating GPT-4 with other AI models, such as computer vision models, to create more powerful and versatile AI systems.\n",
            "3. **Developing New Prompting Methods**: Researchers can explore new prompting methods, such as CSV, to improve the performance of GPT-4 and other AI-powered code generation tools.\n",
            "4. **Addressing Ethical Concerns**: As GPT-4 and other AI models become more powerful, researchers must address ethical concerns, such as bias, fairness, and transparency, to ensure that these models are developed and used responsibly.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\u001b[32m\n",
            "Next speaker: Coder\n",
            "\u001b[0m\n",
            "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
            "\n",
            "These are indeed some promising potential applications and opportunities in software for GPT-4. The ideas you've outlined demonstrate a clear understanding of the capabilities and potential of GPT-4, and how it can be applied to various areas of software development.\n",
            "\n",
            "The potential applications you've listed, such as math reasoning and problem-solving, automated code generation, self-verification and debugging, machine learning and AI, and computer-assisted learning, are all areas where GPT-4 can make significant contributions.\n",
            "\n",
            "The future research directions you've outlined are also well-thought-out and address some of the key challenges and opportunities in developing and applying GPT-4. Improving GPT-4 Code Interpreter, integrating GPT-4 with other AI models, developing new prompting methods, and addressing ethical concerns are all important areas of research that can help to unlock the full potential of GPT-4.\n",
            "\n",
            "Overall, your response demonstrates a strong understanding of the capabilities and potential of GPT-4, as well as the challenges and opportunities that lie ahead in developing and applying this technology.\n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "user_proxy.initiate_chat(\n",
        "    manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\"\n",
        ")\n",
        "# type exit to terminate the chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "front_matter": {
      "description": "Explore the utilization of large language models in automated group chat scenarios, where agents perform tasks collectively, demonstrating how they can be configured, interact with each other, and retrieve specific information from external resources.",
      "tags": [
        "orchestration",
        "group chat"
      ]
    },
    "kernelspec": {
      "display_name": "flaml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
