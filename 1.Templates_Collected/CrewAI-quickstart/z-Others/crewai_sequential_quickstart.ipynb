{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexfazio/crewAI-quickstart/blob/main/crewai_sequential_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# crewai-sequential-quickstart\n",
    "By [Alex Fazio](https://www.x.com/alxfazio)\n",
    "\n",
    "Github repo: https://github.com/alexfazio/crewai-quickstart\n",
    "\n",
    "Docs: https://docs.crewai.com/\n",
    "\n",
    "Simplified and tested version of a **sequential** CrewAI."
   ],
   "metadata": {
    "id": "ANCxcFs-qVl4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üë®‚Äçü¶Ø Run this cell to hide all warnings (optional)\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# To avoid the restart session warning in Colab, exclude the PIL and\n",
    "# pydevd_plugins packages from being imported. This is fine because\n",
    "# we didn't execute the code in the kernel session afterward.\n",
    "\n",
    "# import sys\n",
    "# sys.modules.pop('PIL', None)"
   ],
   "metadata": {
    "id": "NsNLa6Qu0JEK",
    "ExecuteTime": {
     "end_time": "2024-05-17T18:19:19.351863Z",
     "start_time": "2024-05-17T18:19:19.350191Z"
    },
    "cellView": "form"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# @title ‚¨áÔ∏è Install project dependencies by running this cell\n",
    "%pip install git+https://github.com/joaomdmoura/crewAI.git --quiet\n",
    "%pip install crewai_tools langchain_openai langchain_groq langchain_anthropic langchain_community cohere --quiet\n",
    "print(\"---\")\n",
    "%pip show crewAI crewai_tools langchain_openai langchain_groq langchain_anthropic langchain_community cohere"
   ],
   "metadata": {
    "id": "P8iHNKCfk9Rv",
    "ExecuteTime": {
     "end_time": "2024-05-17T18:20:26.741468Z",
     "start_time": "2024-05-17T18:19:29.015624Z"
    },
    "cellView": "form"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BhAt-unGk4kA",
    "ExecuteTime": {
     "end_time": "2024-05-17T18:26:09.810103Z",
     "start_time": "2024-05-17T18:25:59.838229Z"
    },
    "cellView": "form"
   },
   "source": [
    "# @title üîë Input API Key by running this cell\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from textwrap import dedent\n",
    "from langchain_openai import ChatOpenAI\n",
    "# ‚Üë uncomment to use OpenAI's API\n",
    "# from langchain_groq import ChatGroq\n",
    "# ‚Üë uncomment to use Groq's API\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# ‚Üë uncomment to use Antrhopic's API\n",
    "# from langchain_community.chat_models import ChatCohere\n",
    "# ‚Üë uncomment to use ChatCohere API\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OPENAI_API_KEY: \")\n",
    "# ‚Üë uncomment to use OpenAI's API\n",
    "# os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter GROQ_API_KEY: \")\n",
    "# ‚Üë uncomment to use Groq's API\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = getpass(\"Enter ANTHROPIC_API_KEY: \")\n",
    "# ‚Üë uncomment to use Anthropic's API\n",
    "# os.environ[\"COHERE_API_KEY\"] = getpass(\"Enter COHERE_API_KEY: \")\n",
    "# ‚Üë uncomment to use Cohere's API\n",
    "\n",
    "# Check if the 'output-files' directory exists, and create it if it doesn't\n",
    "if not os.path.exists('output-files'):\n",
    "    os.makedirs('output-files')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Agents\n",
    "In CrewAI, agents are autonomous entities designed to perform specific roles and achieve particular goals. Each agent uses a language model (LLM) and may have specialized tools to help execute tasks."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üïµüèª Define your agents\n",
    "\n",
    "# Agent Definitions\n",
    "\n",
    "agent_1 = Agent(\n",
    "    role=dedent((\n",
    "        \"\"\"\n",
    "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
    "        \"\"\")),\n",
    "    backstory=dedent((\n",
    "        \"\"\"\n",
    "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
    "        \"\"\")),\n",
    "    goal=dedent((\n",
    "        \"\"\"\n",
    "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
    "        \"\"\")),\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    # ‚Üë Whether the agent execution should be in verbose mode\n",
    "    max_iter=3,\n",
    "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o\", temperature=0.8)\n",
    "    # ‚Üë uncomment to use OpenAI API + \"gpt-4o\"\n",
    "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
    "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
    "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
    "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
    "    # llm = ChatCohere(model=\"command\", max_tokens=256, temperature=0.75)\n",
    "    # ‚Üë uncomment to use Cohere's API + \"command-r-plus\"\n",
    ")\n",
    "\n",
    "agent_2 = Agent(\n",
    "    role=dedent((\n",
    "        \"\"\"\n",
    "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
    "        \"\"\")),\n",
    "    backstory=dedent((\n",
    "        \"\"\"\n",
    "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
    "        \"\"\")),\n",
    "    goal=dedent((\n",
    "        \"\"\"\n",
    "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
    "        \"\"\")),\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    # ‚Üë Whether the agent execution should be in verbose mode\n",
    "    max_iter=3,\n",
    "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o\", temperature=0.8)\n",
    "    # ‚Üë uncomment to use OpenAI API + \"gpt-4o\"\n",
    "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
    "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
    "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
    "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
    "    # llm = ChatCohere(model=\"command\", max_tokens=256, temperature=0.75)\n",
    "    # ‚Üë uncomment to use Cohere's API + \"command-r-plus\"\n",
    ")\n",
    "\n",
    "agent_3 = Agent(\n",
    "    role=dedent((\n",
    "        \"\"\"\n",
    "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
    "        \"\"\")),\n",
    "    backstory=dedent((\n",
    "        \"\"\"\n",
    "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
    "        \"\"\")),\n",
    "    goal=dedent((\n",
    "        \"\"\"\n",
    "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
    "        \"\"\")),\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    # ‚Üë Whether the agent execution should be in verbose mode\n",
    "    max_iter=3,\n",
    "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o\", temperature=0.8)\n",
    "    # ‚Üë uncomment to use OpenAI API + \"gpt-4o\"\n",
    "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
    "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
    "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
    "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
    "    # llm = ChatCohere(model=\"command\", max_tokens=256, temperature=0.75)\n",
    "    # ‚Üë uncomment to use Cohere's API + \"command-r-plus\"\n",
    ")"
   ],
   "metadata": {
    "id": "hZJwUoXasrhx",
    "ExecuteTime": {
     "end_time": "2024-05-17T18:26:14.680431Z",
     "start_time": "2024-05-17T18:26:14.561004Z"
    },
    "cellView": "form"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Tasks\n",
    "Tasks in CrewAI are specific assignments given to agents, detailing the actions they need to perform to achieve a particular goal. Tasks can have dependencies and context, and can be executed asynchronously to ensure an efficient workflow."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üìù Define your tasks\n",
    "# Task Definitions\n",
    "\n",
    "task_1 = Task(\n",
    "    description=dedent((\n",
    "        \"\"\"\n",
    "        A clear, concise statement of what the task entails.\n",
    "        ---\n",
    "        VARIABLE 1: \"{var_1}\"\n",
    "        VARIABLE 2: \"{var_2}\"\n",
    "        VARIABLE 3: \"{var_3}\"\n",
    "        Add more variables if needed...\n",
    "        \"\"\")),\n",
    "    expected_output=dedent((\n",
    "        \"\"\"\n",
    "        A detailed description of what the task's completion looks like.\n",
    "        \"\"\")),\n",
    "  agent=agent_1,\n",
    ")\n",
    "\n",
    "task_2 = Task(\n",
    "    description=dedent((\n",
    "        \"\"\"\n",
    "        A clear, concise statement of what the task entails.\n",
    "        ---\n",
    "        VARIABLE 1: \"{var_1}\"\n",
    "        VARIABLE 2: \"{var_2}\"\n",
    "        VARIABLE 3: \"{var_3}\"\n",
    "        Add more variables if needed...\n",
    "        \"\"\")),\n",
    "    expected_output=dedent((\n",
    "        f\"\"\"\n",
    "        A detailed description of what the task's completion looks like.\n",
    "        \"\"\")),\n",
    "    agent=agent_2,\n",
    "    context=[task_1],\n",
    "    # ‚Üë specify which task's output should be used as context for subsequent tasks\n",
    ")\n",
    "\n",
    "task_3 = Task(\n",
    "    description=dedent((\n",
    "        \"\"\"\n",
    "        A clear, concise statement of what the task entails.\n",
    "        ---\n",
    "        VARIABLE 1: \"{var_1}\"\n",
    "        VARIABLE 2: \"{var_2}\"\n",
    "        VARIABLE 3: \"{var_3}\"\n",
    "        Add more variables if needed...\n",
    "        \"\"\")),\n",
    "    expected_output=dedent((\n",
    "        \"\"\"\n",
    "        A detailed description of what the task's completion looks like.\n",
    "        \"\"\")),\n",
    "    agent=agent_3,\n",
    "    context=[task_2],\n",
    "    # ‚Üë specify which task's output should be used as context for subsequent tasks\n",
    ")"
   ],
   "metadata": {
    "id": "dqtn3w1qs-Bu",
    "ExecuteTime": {
     "end_time": "2024-05-17T18:26:17.691Z",
     "start_time": "2024-05-17T18:26:17.687416Z"
    },
    "cellView": "form"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# @title ‚å®Ô∏è Define any variables you have and input them\n",
    "print(\"## Welcome to the YOUR_CREW_NAME\")\n",
    "print('-------------------------------------------')\n",
    "var_1 = input(\"What is the  to pass to your crew?\\n\"),\n",
    "var_2 = input(\"What is the  to pass to your crew?\\n\"),\n",
    "var_3 = input(\"What is the  to pass to your crew?\\n\"),\n",
    "print(\"-------------------------------\")"
   ],
   "metadata": {
    "id": "HfJRdGHesMwn",
    "ExecuteTime": {
     "end_time": "2024-05-17T18:26:27.178968Z",
     "start_time": "2024-05-17T18:26:19.601235Z"
    },
    "cellView": "form"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üöÄ Get your crew to work!\n",
    "def main():\n",
    "    # Instantiate your crew with a sequential process\n",
    "    crew = Crew(\n",
    "        agents=[agent_1, agent_2, agent_3],\n",
    "        tasks=[task_1, task_2, task_3],\n",
    "        verbose=True,  # You can set it to True or False\n",
    "        # ‚Üë indicates the verbosity level for logging during execution.\n",
    "        process=Process.sequential\n",
    "        # ‚Üë the process flow that the crew will follow (e.g., sequential, hierarchical).\n",
    "    )\n",
    "\n",
    "    inputs = {\n",
    "    \"var_1\": var_1,\n",
    "    \"var_2\": var_2,\n",
    "    \"var_3\": var_3\n",
    "    }\n",
    "\n",
    "    result = crew.kickoff(inputs=inputs)\n",
    "    print(\"\\n\\n########################\")\n",
    "    print(\"## Here is your custom crew run result:\")\n",
    "    print(\"########################\\n\")\n",
    "    print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  result = main()"
   ],
   "metadata": {
    "id": "nrBn8dMlxfCn",
    "ExecuteTime": {
     "end_time": "2024-05-17T18:26:49.752419Z",
     "start_time": "2024-05-17T18:26:33.273949Z"
    },
    "cellView": "form"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üñ•Ô∏è Display the results of your crew as markdown\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "markdown_text = result.raw  # Adjust this based on the actual attribute\n",
    "\n",
    "# Display the markdown content\n",
    "display(Markdown(markdown_text))"
   ],
   "metadata": {
    "id": "gPQAfHJewy4E",
    "ExecuteTime": {
     "end_time": "2024-05-17T18:31:56.607199Z",
     "start_time": "2024-05-17T18:31:56.602349Z"
    },
    "cellView": "form"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
