{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "authorship_tag": "ABX9TyPcEiT/TYao404NaUBOuVeW",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexfazio/crewAI-quickstart/blob/main/crewai_sequential_DirectoryReadTool_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# crewai-sequential-DirectoryReadTool-quickstart\n",
    "By [Alex Fazio](https://www.x.com/alxfazio)\n",
    "\n",
    "üìÇ Github repo: https://github.com/alexfazio/crewai-quickstart\n",
    "\n",
    "This is a simplified and tested template of a **sequential** CrewAI crew.\n",
    "\n",
    "This crew uses the `DirectoryReadTool` to provide a comprehensive **listing of directory contents**. It can recursively navigate through the specified directory, offering users a detailed enumeration of all files, including those within subdirectories.\n",
    "\n",
    "Check the folder named `./output-files` for detailed results from each task or agent, as well as the initial output from the `DirectoryReadTool`.\n",
    "\n",
    "Extra Requirements:\n",
    "- [OpenAI](https://platform.openai.com/playground)/[Groq](https://console.groq.com/settings/organization)/[Anthropic](https://console.anthropic.com/dashboard) API Key\n",
    "\n",
    "üìö CrewAI docs: https://docs.crewai.com/\n",
    "\n",
    "üìö DirectoryReadTool docs: https://docs.crewai.com/tools/DirectoryReadTool/"
   ],
   "metadata": {
    "id": "ANCxcFs-qVl4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üë®‚Äçü¶Ø Run this cell to hide all warnings (optional)\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# To avoid the restart session warning in Colab, exclude the PIL and\n",
    "# pydevd_plugins packages from being imported. This is fine because\n",
    "# we didn't execute the code in the kernel session afterward.\n",
    "\n",
    "# import sys\n",
    "# sys.modules.pop('PIL', None)"
   ],
   "metadata": {
    "cellView": "form",
    "id": "sxR_zWGJxWTw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title ‚¨áÔ∏è Install project dependencies by running this cell\n",
    "# @markdown  üîÑ Restart the session and rerun the cell **if Colab requires it**.\n",
    "%pip install git+https://github.com/joaomdmoura/crewAI.git --quiet\n",
    "%pip install crewai_tools langchain_openai langchain_groq langchain_anthropic langchain_community cohere --quiet\n",
    "print(\"---\")\n",
    "%pip show crewAI crewai_tools langchain_openai langchain_groq langchain_anthropic langchain_community cohere"
   ],
   "metadata": {
    "id": "P8iHNKCfk9Rv",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhAt-unGk4kA",
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title üîë Input **LLM** API Key by running this cell\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "# from langchain_groq import ChatGroq\n",
    "# ‚Üë Uncomment to use Groq's API\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# ‚Üë Uncomment to use Anthropic's API\n",
    "\n",
    "# Set the OPENAI_API_KEY environment variable by prompting the user to enter the key\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OPENAI_API_KEY: \")\n",
    "# ‚Üë Uncomment to use OpenAI's API\n",
    "# os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter GROQ_API_KEY: \")\n",
    "# ‚Üë Uncomment to use Groq's API\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = getpass(\"Enter ANTHROPIC_API_KEY: \")\n",
    "# ‚Üë Uncomment to use Anthropic's API\n",
    "\n",
    "# Check if the 'output-files' directory exists, and create it if it doesn't\n",
    "if not os.path.exists('output-files'):\n",
    "    os.makedirs('output-files')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üóÇÔ∏è Create a Randomly Generated Sample Folder Structure\n",
    "\n",
    "# @markdown üî° Variables defining the depth and the number of randomly generated folders\n",
    "\n",
    "# @markdown If you don't have a specific preference, please **leave it as it is**.\n",
    "\n",
    "# @markdown This is only for testing.\n",
    "\n",
    "# @title üóÇÔ∏è Create Sample Folder Structure\n",
    "\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "def create_nested_folders(path, depth, max_depth, num_folders, tree_prefix=\"\"):\n",
    "    if depth > max_depth:\n",
    "        return \"\"\n",
    "\n",
    "    tree_structure = \"\"\n",
    "\n",
    "    for i in range(num_folders):\n",
    "        folder_name = ''.join(random.choices(string.ascii_lowercase, k=5))\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        # Create an empty .md file with the specified content\n",
    "        md_file_path = os.path.join(folder_path, \"README.md\")\n",
    "        with open(md_file_path, \"w\") as md_file:\n",
    "            md_file.write(\"Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\")\n",
    "\n",
    "        tree_structure += f\"{tree_prefix}‚îú‚îÄ‚îÄ {folder_name}/\\n\"\n",
    "        tree_structure += create_nested_folders(folder_path, depth + 1, max_depth, num_folders, tree_prefix + \"‚îÇ   \")\n",
    "\n",
    "    return tree_structure\n",
    "\n",
    "# Specify the base directory where the nested folders will be created\n",
    "base_dir = \"/content/nested_folders\"\n",
    "\n",
    "# Remove the base directory if it already exists\n",
    "if os.path.exists(base_dir):\n",
    "    import shutil\n",
    "    shutil.rmtree(base_dir)\n",
    "\n",
    "# Create the base directory\n",
    "os.makedirs(base_dir)\n",
    "\n",
    "# Set the desired depth and number of sub-folders at each level\n",
    "max_depth = 2 # @param {type:\"integer\"}\n",
    "num_folders = 2 # @param {type:\"integer\"}\n",
    "\n",
    "# Create the nested folder structure and generate the visual tree\n",
    "tree = create_nested_folders(base_dir, 1, max_depth, num_folders)\n",
    "\n",
    "print(\"Nested folder structure created successfully.\")\n",
    "print(\"Visual tree representation:\")\n",
    "print(tree)\n",
    "print(\"###\")\n",
    "print(f\"Nested folder structure created successfully in `{base_dir}`.\")"
   ],
   "metadata": {
    "id": "vGtS2Y3AmXm8",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üóÑ Instantiate `DirectoryReadTool`\n",
    "\n",
    "from crewai_tools import DirectoryReadTool\n",
    "\n",
    "# Initialize the tool so the agent can read any directory's content it learns about during execution\n",
    "\n",
    "# tool = DirectoryReadTool()\n",
    "\n",
    "# OR\n",
    "\n",
    "# Initialize the tool with a specific directory, so the agent can only read the content of the specified directory\n",
    "\n",
    "directory_read_tool = DirectoryReadTool(directory=\"./nested_folders\")"
   ],
   "metadata": {
    "id": "IENZ1rmviDZY",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Agents\n",
    "In CrewAI, agents are autonomous entities designed to perform specific roles and achieve particular goals. Each agent uses a language model (LLM) and may have specialized tools to help execute tasks."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üïµüèª Define your agents\n",
    "\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from crewai import Agent\n",
    "from textwrap import dedent\n",
    "\n",
    "# from langchain_groq import ChatGroq\n",
    "# ‚Üë Uncomment to use Groq's API\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# ‚Üë Uncomment to use Anthropic's API\n",
    "\n",
    "agent_1 = Agent(\n",
    "    role=dedent((\n",
    "        \"\"\"\n",
    "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
    "        \"\"\")), # Think of this as the job title\n",
    "    backstory=dedent((\n",
    "        \"\"\"\n",
    "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
    "        \"\"\")), # This is the backstory of the agent, this helps the agent to understand the context of the task\n",
    "    goal=dedent((\n",
    "        \"\"\"\n",
    "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
    "        \"\"\")), # This is the goal that the agent is trying to achieve\n",
    "    tools=[directory_read_tool],\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    # ‚Üë Whether the agent execution should be in verbose mode\n",
    "    max_iter=3,\n",
    "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer (generate the output)\n",
    "    max_rpm=100, # This is the maximum number of requests per minute that the agent can make to the language model\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o\", temperature=0.8)\n",
    "    # ‚Üë uncomment to use OpenAI API + \"gpt-4o\"\n",
    "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
    "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
    "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
    "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
    ")\n",
    "\n",
    "agent_2 = Agent(\n",
    "    role=dedent((\n",
    "        \"\"\"\n",
    "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
    "        \"\"\")), # Think of this as the job title\n",
    "    backstory=dedent((\n",
    "        \"\"\"\n",
    "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
    "        \"\"\")), # This is the backstory of the agent, this helps the agent to understand the context of the task\n",
    "    goal=dedent((\n",
    "        \"\"\"\n",
    "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
    "        \"\"\")), # This is the goal that the agent is trying to achieve\n",
    "    tools=[directory_read_tool],\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    # ‚Üë Whether the agent execution should be in verbose mode\n",
    "    max_iter=3,\n",
    "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer (generate the output)\n",
    "    max_rpm=100, # This is the maximum number of requests per minute that the agent can make to the language model\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o\", temperature=0.8)\n",
    "    # ‚Üë uncomment to use OpenAI API + \"gpt-4o\"\n",
    "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
    "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
    "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
    "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
    ")\n",
    "\n",
    "agent_3 = Agent(\n",
    "    role=dedent((\n",
    "        \"\"\"\n",
    "        Defines the agent's function within the crew. It determines the kind of tasks the agent is best suited for.\n",
    "        \"\"\")), # Think of this as the job title\n",
    "    backstory=dedent((\n",
    "        \"\"\"\n",
    "        Provides context to the agent's role and goal, enriching the interaction and collaboration dynamics.\n",
    "        \"\"\")), # This is the backstory of the agent, this helps the agent to understand the context of the task\n",
    "    goal=dedent((\n",
    "        \"\"\"\n",
    "        The individual objective that the agent aims to achieve. It guides the agent's decision-making process.\n",
    "        \"\"\")), # This is the goal that the agent is trying to achieve\n",
    "    tools=[directory_read_tool],\n",
    "    allow_delegation=False,\n",
    "    verbose=True,\n",
    "    # ‚Üë Whether the agent execution should be in verbose mode\n",
    "    max_iter=3,\n",
    "    # ‚Üë maximum number of iterations the agent can perform before being forced to give its best answer (generate the output)\n",
    "    max_rpm=100, # This is the maximum number of requests per minute that the agent can make to the language model\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o\", temperature=0.8)\n",
    "    # ‚Üë uncomment to use OpenAI API + \"gpt-4o\"\n",
    "    # llm=ChatGroq(temperature=0.8, model_name=\"mixtral-8x7b-32768\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"llama3-70b-8192\"\n",
    "    # llm=ChatGroq(temperature=0.6, model_name=\"llama3-70b-8192\"),\n",
    "    # ‚Üë uncomment to use Groq's API + \"mixtral-8x7b-32768\"\n",
    "    # llm = ChatAnthropic(model='claude-3-opus-20240229', temperature=0.8),\n",
    "    # ‚Üë uncomment to use Anthropic's API + \"claude-3-opus-20240229\"\n",
    ")\n"
   ],
   "metadata": {
    "id": "hZJwUoXasrhx",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Define Tasks\n",
    "Tasks in CrewAI are specific assignments given to agents, detailing the actions they need to perform to achieve a particular goal. Tasks can have dependencies and context, and can be executed asynchronously to ensure an efficient workflow."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üìù Define your tasks\n",
    "\n",
    "import datetime\n",
    "from crewai import Task\n",
    "\n",
    "task_1 = Task(\n",
    "    description=dedent((\n",
    "        \"\"\"\n",
    "        A clear, concise statement of what the task entails.\n",
    "        ---\n",
    "        VARIABLE 1: \"{var_1}\"\n",
    "        VARIABLE 2: \"{var_2}\"\n",
    "        VARIABLE 3: \"{var_3}\"\n",
    "        Add more variables if needed...\n",
    "        \"\"\")),\n",
    "    expected_output=dedent((\n",
    "        \"\"\"\n",
    "        A detailed description of what the task's completion looks like.\n",
    "        \"\"\")),\n",
    "    agent=agent_1,\n",
    "    # output_file='blog-posts/new_post.md'  # The final blog post will be saved here\n",
    "    output_file=f'output-files/agent_1-output_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.md'\n",
    ")\n",
    "\n",
    "task_2 = Task(\n",
    "    description=dedent((\n",
    "        \"\"\"\n",
    "        A clear, concise statement of what the task entails.\n",
    "        ---\n",
    "        VARIABLE 1: \"{var_1}\"\n",
    "        VARIABLE 2: \"{var_2}\"\n",
    "        VARIABLE 3: \"{var_3}\"\n",
    "        Add more variables if needed...\n",
    "        \"\"\")),\n",
    "    expected_output=dedent((\n",
    "        \"\"\"\n",
    "        A detailed description of what the task's completion looks like.\n",
    "        \"\"\")),\n",
    "    agent=agent_2,\n",
    "    context=[task_1],\n",
    "    # ‚Üë specify which task's output should be used as context for subsequent tasks\n",
    "    output_file=f'output-files/agent_2-output_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.md'\n",
    ")\n",
    "\n",
    "task_3 = Task(\n",
    "    description=dedent((\n",
    "        \"\"\"\n",
    "        A clear, concise statement of what the task entails.\n",
    "        ---\n",
    "        VARIABLE 1: \"{var_1}\"\n",
    "        VARIABLE 2: \"{var_2}\"\n",
    "        VARIABLE 3: \"{var_3}\"\n",
    "        Add more variables if needed...\n",
    "        \"\"\")),\n",
    "    expected_output=dedent((\n",
    "        \"\"\"\n",
    "        A detailed description of what the task's completion looks like.\n",
    "        \"\"\")),\n",
    "    agent=agent_3,\n",
    "    context=[task_2],\n",
    "    # ‚Üë specify which task's output should be used as context for subsequent tasks\n",
    "    output_file=f'output-files/agent_3-output_{datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.md'\n",
    ")"
   ],
   "metadata": {
    "id": "dqtn3w1qs-Bu",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title ‚å®Ô∏è Define any variables you have and input them\n",
    "print(\"## Welcome to the YOUR_CREW_NAME\")\n",
    "print('-------------------------------------------')\n",
    "var_1 = input(\"What is the  to pass to your crew?\\n\"),\n",
    "var_2 = input(\"What is the  to pass to your crew?\\n\"),\n",
    "var_3 = input(\"What is the  to pass to your crew?\\n\"),\n",
    "print(\"-------------------------------\")"
   ],
   "metadata": {
    "id": "HfJRdGHesMwn",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üöÄ Get your crew to work!\n",
    "\n",
    "from crewai import Crew, Process\n",
    "\n",
    "def main():\n",
    "    # Instantiate your crew with a sequential process\n",
    "    crew = Crew(\n",
    "        agents=[agent_1, agent_2, agent_3],\n",
    "        tasks=[task_1, task_2, task_3],\n",
    "        verbose=True,  # You can set it to True or False\n",
    "        # ‚Üë indicates the verbosity level for logging during execution.\n",
    "        process=Process.sequential\n",
    "        # ‚Üë the process flow that the crew will follow (e.g., sequential, hierarchical).\n",
    "    )\n",
    "\n",
    "    inputs = {\n",
    "    \"var_1\": var_1,\n",
    "    \"var_2\": var_2,\n",
    "    \"var_3\": var_3\n",
    "    }\n",
    "\n",
    "    result = crew.kickoff(inputs=inputs)\n",
    "    print(\"\\n\\n########################\")\n",
    "    print(\"## Here is your custom crew run result:\")\n",
    "    print(\"########################\\n\")\n",
    "    print(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  result = main()"
   ],
   "metadata": {
    "id": "nrBn8dMlxfCn",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title üñ•Ô∏è Display the results of your crew as markdown\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "markdown_text = result.raw  # Adjust this based on the actual attribute\n",
    "\n",
    "# Display the markdown content\n",
    "display(Markdown(markdown_text))"
   ],
   "metadata": {
    "id": "KRJyXDc9xMCL"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
