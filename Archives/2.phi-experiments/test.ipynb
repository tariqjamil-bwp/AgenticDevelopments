{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "#from ollama import ChatOllama\n",
    "client = Groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! It's nice to meet you! Is there something I can help you with, or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(model=\"llama3-70b-8192\", messages=[{\"role\": \"user\", \"content\": \"Hello!\"}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq is a novel machine learning (ML) acceleration platform that speeds up the inference of ML models, making them more efficient and scalable. Here's how it accelerates ML models:\n",
      "\n",
      "**1. Compiler-based Optimization**: Groq uses a compiler-based approach to optimize ML models. It takes in a trained ML model, analyzes its architecture, and generates optimized machine code that can run efficiently on the target hardware. This optimization process reduces the computational overhead, memory access, and memory usage, resulting in significant speedups.\n",
      "\n",
      "**2. Tensor Compilation**: Groq's compiler compiles ML models into an intermediate representation (IR) called \"tensors\". These tensors are then optimized and scheduled to minimize memory access, data movement, and computation. This tensor compilation enables Groq to apply various optimizations, such as fusion, tiling, and register blocking, to reduce the computational overhead.\n",
      "\n",
      "**3. Hardware-Aware Optimization**: Groq's compiler is aware of the underlying hardware architecture, including the number of cores, cache hierarchies, and memory bandwidth. It optimizes the ML model to maximize the utilization of the available hardware resources, ensuring that the model runs efficiently on the target hardware.\n",
      "\n",
      "**4. Parallelization and Pipelining**: Groq parallelizes the ML model's computation across multiple cores and accelerators, such as GPUs, FPGAs, or ASICs. It also pipelines the computation to minimize dependencies and maximize throughput. This parallelization and pipelining enable Groq to process large batches of data in parallel, leading to significant speedups.\n",
      "\n",
      "**5. Memory Optimization**: Groq optimizes memory access patterns to reduce memory bandwidth usage and minimize page faults. It uses techniques like data compression, caching, and buffering to reduce memory traffic and improve data locality.\n",
      "\n",
      "**6. Quantization and Pruning**: Groq can optionally apply quantization and pruning techniques to reduce the precision of the ML model's weights and activations. This reduces the computational overhead, memory usage, and energy consumption, while maintaining model accuracy.\n",
      "\n",
      "**7. Runtime Optimization**: Groq's runtime environment continuously monitors the ML model's performance and adapts to changing workloads. It dynamically adjusts the batch size, parallelization degree, and other parameters to ensure optimal performance and efficiency.\n",
      "\n",
      "By applying these optimizations, Groq can accelerate ML models by 10-100x compared to traditional software-based inference engines, making it an attractive solution for deploying ML models in production environments.\n"
     ]
    }
   ],
   "source": [
    "class GroqLLM:\n",
    "    def __init__(self, api_key=None, model=\"llama3-70b-8192\"):\n",
    "        \"\"\"\n",
    "        Initialize the GroqAPI client with an API key and optional model name.\n",
    "        \"\"\"\n",
    "        from groq import Client  # Import inside class to avoid issues if not installed globally\n",
    "        import os\n",
    "        api_key = os.environ.get(\"GROQ_API_KEY\", api_key)\n",
    "        self.client = Client(api_key=api_key)\n",
    "        self.model = model\n",
    "\n",
    "    def chat(self, prompt):\n",
    "        \"\"\"\n",
    "        Send a prompt to the model and return the response.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            # Extract and return the assistant's reply\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = \"your_groq_api_key\"  # Replace with your actual Groq API key\n",
    "    groq = GroqLLM(api_key=api_key)\n",
    "\n",
    "    prompt = \"Explain how Groq accelerates machine learning models.\"\n",
    "    response = groq.chat(prompt)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad96c890bfe47f885ba61ab82e65b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from phi.assistant import Assistant\n",
    "from phi.tools.duckduckgo import DuckDuckGo\n",
    "from phi.assistant import Assistant\n",
    "from phi.llm.groq import Groq\n",
    "from phi.tools.calculator import Calculator\n",
    "\n",
    "llm=Groq(model=\"mixtral-8x7b-32768\")\n",
    "assistant = Assistant(\n",
    "    llm=llm,\n",
    "    description=\"You help people with their health and fitness goals.\",\n",
    "    # debug_mode=True,\n",
    ")\n",
    "assistant.print_response(\"Share a quick healthy breakfast recipe.\", markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisTools import currency_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Currency_converter(amount:float, base_currency:str, quote_currency:str)-> float:\n",
    "    \"\"\"AI is creating summary for Currency_converter\n",
    "\n",
    "    Args:\n",
    "        amount (float): [description]\n",
    "        base_currency (str): [description]\n",
    "        quote_currency (str): [description]\n",
    "\n",
    "    Returns:\n",
    "        float: [description]\n",
    "    \"\"\"\n",
    "    return currency_converter(amount=amount, source_curr=base_currency, target_curr=quote_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> TOOL-CURRENCY_CONVERTER CALLED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'10.00 USD is equivalent to: 7.47 GBP'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Currency_converter(10,'USD', 'GBP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [Calculator(), DuckDuckGo(), Currency_converter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a22e6b99b5347aa9839f5f7fdd8a03e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant = Assistant(tools=tools, show_tool_calls=True, llm=llm)\n",
    "assistant.print_response(\"I bought 10 bananas at .2 USD per unit, and apples per unit cst is .5usd . If the total bill is 10 USD, the howm many apples I purchased\", markdown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f3d09614704937abc2962267183b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">-&gt; TOOL-CURRENCY_CONVERTER CALLED\n",
       "</pre>\n"
      ],
      "text/plain": [
       "-> TOOL-CURRENCY_CONVERTER CALLED\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant = Assistant(tools=tools, show_tool_calls=True, llm=llm)\n",
    "assistant.print_response(\"Also what is 1USD to GBP\", markdown=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agents-4yRd6dJo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
